{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9510c8cf",
   "metadata": {},
   "source": [
    "\n",
    "# code copied from kaggle notebook, and made changes on top of it\n",
    "# https://www.kaggle.com/competitions/optiver-realized-volatility-prediction/discussion/274970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e45c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from IPython.display import display\n",
    "from joblib import delayed, Parallel\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "from darts import TimeSeries\n",
    "from darts.models import TCNModel, RNNModel, ExponentialSmoothing, BlockRNNModel, NBEATSModel, TransformerModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.metrics import mape, r2_score\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "from darts.datasets import AirPassengersDataset, SunspotsDataset, EnergyDataset\n",
    "from darts.metrics import mae, rmse, mse, mape\n",
    "import random\n",
    "from typing import List, Tuple, Optional, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import torch.optim as optim\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "import darts.utils.timeseries_generation as tg\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# DATA_DIR = '../input'\n",
    "# DATA_DIR = './datasets'\n",
    "DATA_DIR = '/Users/pujanmaharjan/uni adelaide/uofa_research_project/datasets'\n",
    "\n",
    "# data configurations\n",
    "USE_PRECOMPUTE_FEATURES = True  # Load precomputed features for train.csv from private dataset (just for speed up)\n",
    "\n",
    "# model & ensemble configurations\n",
    "PREDICT_CNN = True\n",
    "PREDICT_MLP = True\n",
    "PREDICT_GBDT = True\n",
    "PREDICT_TABNET = False\n",
    "\n",
    "GBDT_NUM_MODELS = 3\n",
    "GBDT_LR = 0.02  # 0.1\n",
    "\n",
    "NN_VALID_TH = 0.185\n",
    "NN_MODEL_TOP_N = 3\n",
    "TAB_MODEL_TOP_N = 3\n",
    "ENSEMBLE_METHOD = 'mean'\n",
    "NN_NUM_MODELS = 10\n",
    "TABNET_NUM_MODELS = 5\n",
    "\n",
    "# for saving quota\n",
    "IS_1ST_STAGE = True\n",
    "SHORTCUT_NN_IN_1ST_STAGE = True  # early-stop training to save GPU quota\n",
    "SHORTCUT_GBDT_IN_1ST_STAGE = True\n",
    "MEMORY_TEST_MODE = False\n",
    "\n",
    "# for ablation studies\n",
    "CV_SPLIT = 'time'  # 'time': time-series KFold 'group': GroupKFold by stock-id\n",
    "USE_PRICE_NN_FEATURES = True  # Use nearest neighbor features that rely on tick size\n",
    "USE_VOL_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_SIZE_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_RANDOM_NN_FEATURES = False  # Use random index to aggregate neighbors\n",
    "\n",
    "USE_TIME_ID_NN = True  # Use time-id based neighbors\n",
    "USE_STOCK_ID_NN = True  # Use stock-id based neighbors\n",
    "\n",
    "ENABLE_RANK_NORMALIZATION = True  # Enable rank-normalization\n",
    "\n",
    "EPOCHS = 2\n",
    "SEED = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1540aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_into_train_test(df):\n",
    "    train_index = int(len(df) * 0.8)\n",
    "    train_data = df[:train_index]\n",
    "    test_data = df[train_index:]\n",
    "    print('Train data shape ', train_data.shape)\n",
    "    print('Test data shape ', test_data.shape)\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def split_df_into_train_val_test(df):\n",
    "    # split 70, 15, 15\n",
    "    train_index = int(len(df) * 0.7)\n",
    "    train_data = df[:train_index]\n",
    "    val_test_data = df[train_index:]\n",
    "    val_index = int(len(val_test_data) * 0.5)\n",
    "    val_data = val_test_data[:val_index]\n",
    "    test_data = val_test_data[val_index:]\n",
    "    print('Total data shape ', df.shape)\n",
    "    print('train shape ', train_data.shape)\n",
    "    print('validation shape ', val_data.shape)\n",
    "    print('test shape ', test_data.shape)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f'[{name}] {elapsed: .3f}sec')\n",
    "    \n",
    "def print_trace(name: str = ''):\n",
    "    print(f'ERROR RAISED IN {name or \"anonymous\"}')\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "# import pickle\n",
    "# def pickle_dumps(file_name, data):\n",
    "#     with open(file_name, 'wb') as f:\n",
    "#         pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# def pickle_load(file_name):\n",
    "#     with open(file_name, 'rb') as f:\n",
    "#         return pickle.load(f)\n",
    "\n",
    "# def read_x_y():\n",
    "#     X = pd.read_csv('./data-cache/X.csv')\n",
    "#     y = pd.read_csv(\"./data-cache/y.csv\")\n",
    "\n",
    "#     print('X.shape ', X.shape)\n",
    "#     print('y.shape ', y.shape)\n",
    "\n",
    "#     return X, y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e67a8c8",
   "metadata": {
    "papermill": {
     "duration": 0.030693,
     "end_time": "2022-01-23T02:26:30.479103",
     "exception": false,
     "start_time": "2022-01-23T02:26:30.448410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Base Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9bcf32",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:30.573125Z",
     "iopub.status.busy": "2022-01-23T02:26:30.553308Z",
     "iopub.status.idle": "2022-01-23T02:26:30.575466Z",
     "shell.execute_reply": "2022-01-23T02:26:30.575064Z",
     "shell.execute_reply.started": "2022-01-19T11:20:47.920189Z"
    },
    "papermill": {
     "duration": 0.067985,
     "end_time": "2022-01-23T02:26:30.575573",
     "exception": false,
     "start_time": "2022-01-23T02:26:30.507588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataBlock(Enum):\n",
    "    TRAIN = 1\n",
    "    TEST = 2\n",
    "    BOTH = 3\n",
    "\n",
    "def load_stock_data(stock_id: int, directory: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', directory, f'stock_id={stock_id}'))\n",
    "\n",
    "def load_data(stock_id: int, stem: str, block: DataBlock) -> pd.DataFrame:\n",
    "    if block == DataBlock.TRAIN:\n",
    "        return load_stock_data(stock_id, f'{stem}_train.parquet')\n",
    "    elif block == DataBlock.TEST:\n",
    "        return load_stock_data(stock_id, f'{stem}_test.parquet')\n",
    "    else:\n",
    "        return pd.concat([\n",
    "            load_data(stock_id, stem, DataBlock.TRAIN),\n",
    "            load_data(stock_id, stem, DataBlock.TEST)\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "def load_book(stock_id: int, block: DataBlock=DataBlock.TRAIN) -> pd.DataFrame:\n",
    "    return load_data(stock_id, 'book', block)\n",
    "\n",
    "def load_trade(stock_id: int, block=DataBlock.TRAIN) -> pd.DataFrame:\n",
    "    return load_data(stock_id, 'trade', block)\n",
    "\n",
    "def calc_wap1(df: pd.DataFrame) -> pd.Series:\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap2(df: pd.DataFrame) -> pd.Series:\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "def log_return(series: np.ndarray):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "def log_return_df2(series: np.ndarray):\n",
    "    return np.log(series).diff(2)\n",
    "\n",
    "def flatten_name(prefix, src_names):\n",
    "    ret = []\n",
    "    for c in src_names:\n",
    "        if c[0] in ['time_id', 'stock_id']:\n",
    "            ret.append(c[0])\n",
    "        else:\n",
    "            ret.append('.'.join([prefix] + list(c)))\n",
    "    return ret\n",
    "\n",
    "def make_book_feature(stock_id, block = DataBlock.TRAIN, \n",
    "                      add_spread_features = False,\n",
    "                      add_statistics_features = False):\n",
    "    book = load_book(stock_id, block)\n",
    "\n",
    "    book['wap1'] = calc_wap1(book)\n",
    "    book['wap2'] = calc_wap2(book)\n",
    "    book['log_return1'] = book.groupby(['time_id'], group_keys=False)['wap1'].apply(log_return)\n",
    "    book['log_return2'] = book.groupby(['time_id'], group_keys=False)['wap2'].apply(log_return)\n",
    "    book['log_return_ask1'] = book.groupby(['time_id'], group_keys=False)['ask_price1'].apply(log_return)\n",
    "    book['log_return_ask2'] = book.groupby(['time_id'], group_keys=False)['ask_price2'].apply(log_return)\n",
    "    book['log_return_bid1'] = book.groupby(['time_id'], group_keys=False)['bid_price1'].apply(log_return)\n",
    "    book['log_return_bid2'] = book.groupby(['time_id'], group_keys=False)['bid_price2'].apply(log_return)\n",
    "\n",
    "    if add_spread_features:\n",
    "        book['wap_balance'] = abs(book['wap1'] - book['wap2'])\n",
    "        book['price_spread'] = (book['ask_price1'] - book['bid_price1']) / ((book['ask_price1'] + book['bid_price1']) / 2)\n",
    "        book['bid_spread'] = book['bid_price1'] - book['bid_price2']\n",
    "        book['ask_spread'] = book['ask_price1'] - book['ask_price2']\n",
    "        book['total_volume'] = (book['ask_size1'] + book['ask_size2']) + (book['bid_size1'] + book['bid_size2'])\n",
    "        book['volume_imbalance'] = abs((book['ask_size1'] + book['ask_size2']) - (book['bid_size1'] + book['bid_size2']))\n",
    "\n",
    "    features = {\n",
    "        'wap1': [np.sum],\n",
    "        'wap2': [np.sum],\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return_ask1': [realized_volatility],\n",
    "        'log_return_ask2': [realized_volatility],\n",
    "        'log_return_bid1': [realized_volatility],\n",
    "        'log_return_bid2': [realized_volatility],\n",
    "    }\n",
    "\n",
    "    if add_spread_features and add_statistics_features:\n",
    "        features = {\n",
    "            'seconds_in_bucket': ['count'],\n",
    "            'wap1': [np.sum, np.mean, np.std],\n",
    "            'wap2': [np.sum, np.mean, np.std],\n",
    "            'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "            'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "            'log_return_ask1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "            'log_return_ask2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "            'log_return_bid1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "            'log_return_bid2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "            'wap_balance': [np.sum, np.mean, np.std],\n",
    "            'price_spread':[np.sum, np.mean, np.std],\n",
    "            'bid_spread':[np.sum, np.mean, np.std],\n",
    "            'ask_spread':[np.sum, np.mean, np.std],\n",
    "            'total_volume':[np.sum, np.mean, np.std],\n",
    "            'volume_imbalance':[np.sum, np.mean, np.std]\n",
    "        }\n",
    "    elif add_spread_features and not add_statistics_features:\n",
    "        features = {\n",
    "            'seconds_in_bucket': ['count'],\n",
    "            'wap1': [np.sum],\n",
    "            'wap2': [np.sum],\n",
    "            'log_return1': [realized_volatility],\n",
    "            'log_return2': [realized_volatility],\n",
    "            'log_return_ask1': [np.sum, realized_volatility],\n",
    "            'log_return_ask2': [np.sum, realized_volatility],\n",
    "            'log_return_bid1': [np.sum, realized_volatility],\n",
    "            'log_return_bid2': [np.sum, realized_volatility],\n",
    "            'wap_balance': [np.sum],\n",
    "            'price_spread':[np.sum],\n",
    "            'bid_spread':[np.sum],\n",
    "            'ask_spread':[np.sum],\n",
    "            'total_volume':[np.sum],\n",
    "            'volume_imbalance':[np.sum]\n",
    "        }\n",
    "\n",
    "    \n",
    "    agg = book.groupby('time_id', group_keys=False).agg(features).reset_index(drop=False)\n",
    "    agg.columns = flatten_name('book', agg.columns)\n",
    "    agg['stock_id'] = stock_id\n",
    "    \n",
    "    # for time in [450, 300, 150]:\n",
    "    #     d = book[book['seconds_in_bucket'] >= time].groupby('time_id', group_keys=False).agg(features).reset_index(drop=False)\n",
    "    #     d.columns = flatten_name(f'book_{time}', d.columns)\n",
    "    #     agg = pd.merge(agg, d, on='time_id', how='left')\n",
    "    return agg\n",
    "\n",
    "def make_trade_feature(stock_id, block = DataBlock.TRAIN):\n",
    "    trade = load_trade(stock_id, block)\n",
    "    trade['log_return'] = trade.groupby('time_id', group_keys=False)['price'].apply(log_return)\n",
    "\n",
    "    features = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':['count'],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "    }\n",
    "\n",
    "    agg = trade.groupby('time_id', group_keys=False).agg(features).reset_index()\n",
    "    agg.columns = flatten_name('trade', agg.columns)\n",
    "    agg['stock_id'] = stock_id\n",
    "        \n",
    "    # for time in [450, 300, 150]:\n",
    "    #     d = trade[trade['seconds_in_bucket'] >= time].groupby('time_id').agg(features).reset_index(drop=False)\n",
    "    #     d.columns = flatten_name(f'trade_{time}', d.columns)\n",
    "    #     agg = pd.merge(agg, d, on='time_id', how='left')\n",
    "    return agg\n",
    "\n",
    "def make_book_feature_v2(stock_id, block = DataBlock.TRAIN):\n",
    "    book = load_book(stock_id, block)\n",
    "\n",
    "    prices = book.set_index('time_id')[['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2']]\n",
    "    time_ids = list(set(prices.index))\n",
    "\n",
    "    ticks = {}\n",
    "    for tid in time_ids:\n",
    "        try:\n",
    "            price_list = prices.loc[tid].values.flatten()\n",
    "            price_diff = sorted(np.diff(sorted(set(price_list))))\n",
    "            ticks[tid] = price_diff[0]\n",
    "        except Exception:\n",
    "            print_trace(f'tid={tid}')\n",
    "            ticks[tid] = np.nan\n",
    "        \n",
    "    dst = pd.DataFrame()\n",
    "    dst['time_id'] = np.unique(book['time_id'])\n",
    "    dst['stock_id'] = stock_id\n",
    "    dst['tick_size'] = dst['time_id'].map(ticks)\n",
    "\n",
    "    return dst\n",
    "\n",
    "def make_features(base, block, add_spread_features = False, add_statistics_features = False):\n",
    "    stock_ids = set(base['stock_id'])\n",
    "    with timer('books'):\n",
    "        books = Parallel(n_jobs=-1)(delayed(make_book_feature)(i, block, add_spread_features, add_statistics_features) for i in stock_ids)\n",
    "        book = pd.concat(books)\n",
    "\n",
    "    with timer('trades'):\n",
    "        trades = Parallel(n_jobs=-1)(delayed(make_trade_feature)(i, block) for i in stock_ids)\n",
    "        trade = pd.concat(trades)\n",
    "\n",
    "    with timer('extra features'):\n",
    "        df = pd.merge(base, book, on=['stock_id', 'time_id'], how='left')\n",
    "        df = pd.merge(df, trade, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "    return df\n",
    "\n",
    "def make_features_v2(base, block):\n",
    "    stock_ids = set(base['stock_id'])\n",
    "    with timer('books(v2)'):\n",
    "        books = Parallel(n_jobs=-1)(delayed(make_book_feature_v2)(i, block) for i in stock_ids)\n",
    "        book_v2 = pd.concat(books)\n",
    "\n",
    "    d = pd.merge(base, book_v2, on=['stock_id', 'time_id'], how='left')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d745fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002353</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002353</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917548</th>\n",
       "      <td>32767</td>\n",
       "      <td>568</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.997796</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917549</th>\n",
       "      <td>32767</td>\n",
       "      <td>569</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.997892</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917550</th>\n",
       "      <td>32767</td>\n",
       "      <td>571</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.997892</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917551</th>\n",
       "      <td>32767</td>\n",
       "      <td>572</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.997892</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917552</th>\n",
       "      <td>32767</td>\n",
       "      <td>582</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.998179</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917553 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  \\\n",
       "0             5                  0    1.001422    1.002301    1.001370   \n",
       "1             5                  1    1.001422    1.002301    1.001370   \n",
       "2             5                  5    1.001422    1.002301    1.001370   \n",
       "3             5                  6    1.001422    1.002301    1.001370   \n",
       "4             5                  7    1.001422    1.002301    1.001370   \n",
       "...         ...                ...         ...         ...         ...   \n",
       "917548    32767                568    0.998275    0.998754    0.997796   \n",
       "917549    32767                569    0.998275    0.998754    0.997892   \n",
       "917550    32767                571    0.998275    0.998754    0.997892   \n",
       "917551    32767                572    0.998275    0.998754    0.997892   \n",
       "917552    32767                582    0.998275    0.998754    0.998179   \n",
       "\n",
       "        ask_price2  bid_size1  ask_size1  bid_size2  ask_size2  \n",
       "0         1.002353          3        226          2        100  \n",
       "1         1.002353          3        100          2        100  \n",
       "2         1.002405          3        100          2        100  \n",
       "3         1.002405          3        126          2        100  \n",
       "4         1.002405          3        126          2        100  \n",
       "...            ...        ...        ...        ...        ...  \n",
       "917548    0.998946         90         90         48         28  \n",
       "917549    0.998946         91         90        200         28  \n",
       "917550    0.998946         91         90        100         28  \n",
       "917551    0.998946         92         90        100         28  \n",
       "917552    0.998946         92         90         26         28  \n",
       "\n",
       "[917553 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df = load_book(0, DataBlock.TRAIN)\n",
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1087ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>book.wap1.sum</th>\n",
       "      <th>book.wap2.sum</th>\n",
       "      <th>book.log_return1.realized_volatility</th>\n",
       "      <th>book.log_return2.realized_volatility</th>\n",
       "      <th>book.log_return_ask1.realized_volatility</th>\n",
       "      <th>book.log_return_ask2.realized_volatility</th>\n",
       "      <th>book.log_return_bid1.realized_volatility</th>\n",
       "      <th>book.log_return_bid2.realized_volatility</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>303.125061</td>\n",
       "      <td>303.105539</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>200.047768</td>\n",
       "      <td>200.041171</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>187.913849</td>\n",
       "      <td>187.939824</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>119.859781</td>\n",
       "      <td>119.835941</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>175.932865</td>\n",
       "      <td>175.934256</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>32751</td>\n",
       "      <td>296.387479</td>\n",
       "      <td>296.365481</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>32753</td>\n",
       "      <td>206.063903</td>\n",
       "      <td>206.100395</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>32758</td>\n",
       "      <td>187.915689</td>\n",
       "      <td>187.897700</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>32763</td>\n",
       "      <td>307.723687</td>\n",
       "      <td>307.732623</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>32767</td>\n",
       "      <td>227.800017</td>\n",
       "      <td>227.809904</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_id  book.wap1.sum  book.wap2.sum  \\\n",
       "0           5     303.125061     303.105539   \n",
       "1          11     200.047768     200.041171   \n",
       "2          16     187.913849     187.939824   \n",
       "3          31     119.859781     119.835941   \n",
       "4          62     175.932865     175.934256   \n",
       "...       ...            ...            ...   \n",
       "3825    32751     296.387479     296.365481   \n",
       "3826    32753     206.063903     206.100395   \n",
       "3827    32758     187.915689     187.897700   \n",
       "3828    32763     307.723687     307.732623   \n",
       "3829    32767     227.800017     227.809904   \n",
       "\n",
       "      book.log_return1.realized_volatility  \\\n",
       "0                                 0.004499   \n",
       "1                                 0.001204   \n",
       "2                                 0.002369   \n",
       "3                                 0.002574   \n",
       "4                                 0.001894   \n",
       "...                                    ...   \n",
       "3825                              0.002579   \n",
       "3826                              0.002206   \n",
       "3827                              0.002913   \n",
       "3828                              0.003046   \n",
       "3829                              0.001901   \n",
       "\n",
       "      book.log_return2.realized_volatility  \\\n",
       "0                                 0.006999   \n",
       "1                                 0.002476   \n",
       "2                                 0.004801   \n",
       "3                                 0.003637   \n",
       "4                                 0.003257   \n",
       "...                                    ...   \n",
       "3825                              0.003821   \n",
       "3826                              0.002847   \n",
       "3827                              0.003266   \n",
       "3828                              0.005105   \n",
       "3829                              0.002541   \n",
       "\n",
       "      book.log_return_ask1.realized_volatility  \\\n",
       "0                                     0.002476   \n",
       "1                                     0.000928   \n",
       "2                                     0.001753   \n",
       "3                                     0.001225   \n",
       "4                                     0.001075   \n",
       "...                                        ...   \n",
       "3825                                  0.001993   \n",
       "3826                                  0.001128   \n",
       "3827                                  0.001661   \n",
       "3828                                  0.002202   \n",
       "3829                                  0.001656   \n",
       "\n",
       "      book.log_return_ask2.realized_volatility  \\\n",
       "0                                     0.002684   \n",
       "1                                     0.000761   \n",
       "2                                     0.002744   \n",
       "3                                     0.001358   \n",
       "4                                     0.001080   \n",
       "...                                        ...   \n",
       "3825                                  0.001873   \n",
       "3826                                  0.001265   \n",
       "3827                                  0.001552   \n",
       "3828                                  0.003330   \n",
       "3829                                  0.001575   \n",
       "\n",
       "      book.log_return_bid1.realized_volatility  \\\n",
       "0                                     0.002602   \n",
       "1                                     0.001029   \n",
       "2                                     0.001553   \n",
       "3                                     0.001989   \n",
       "4                                     0.001343   \n",
       "...                                        ...   \n",
       "3825                                  0.000991   \n",
       "3826                                  0.001051   \n",
       "3827                                  0.002215   \n",
       "3828                                  0.001915   \n",
       "3829                                  0.001485   \n",
       "\n",
       "      book.log_return_bid2.realized_volatility  stock_id  \n",
       "0                                     0.003072         0  \n",
       "1                                     0.001292         0  \n",
       "2                                     0.002005         0  \n",
       "3                                     0.002612         0  \n",
       "4                                     0.001377         0  \n",
       "...                                        ...       ...  \n",
       "3825                                  0.000775         0  \n",
       "3826                                  0.001058         0  \n",
       "3827                                  0.002782         0  \n",
       "3828                                  0.002334         0  \n",
       "3829                                  0.002039         0  \n",
       "\n",
       "[3830 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_train_df = make_book_feature(0, DataBlock.TRAIN)\n",
    "book_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c606639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1.002778</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.002818</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>1.003155</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>1.003646</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123438</th>\n",
       "      <td>32767</td>\n",
       "      <td>471</td>\n",
       "      <td>0.998659</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123439</th>\n",
       "      <td>32767</td>\n",
       "      <td>517</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123440</th>\n",
       "      <td>32767</td>\n",
       "      <td>523</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123441</th>\n",
       "      <td>32767</td>\n",
       "      <td>542</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123442</th>\n",
       "      <td>32767</td>\n",
       "      <td>567</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123443 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_id  seconds_in_bucket     price  size  order_count\n",
       "0             5                 21  1.002301   326           12\n",
       "1             5                 46  1.002778   128            4\n",
       "2             5                 50  1.002818    55            1\n",
       "3             5                 57  1.003155   121            5\n",
       "4             5                 68  1.003646     4            1\n",
       "...         ...                ...       ...   ...          ...\n",
       "123438    32767                471  0.998659   200            3\n",
       "123439    32767                517  0.998515    90            1\n",
       "123440    32767                523  0.998563     1            1\n",
       "123441    32767                542  0.998803    90            4\n",
       "123442    32767                567  0.998547   300            3\n",
       "\n",
       "[123443 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_df = load_trade(0, DataBlock.TRAIN)\n",
    "trade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33be8fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>trade.log_return.realized_volatility</th>\n",
       "      <th>trade.seconds_in_bucket.count</th>\n",
       "      <th>trade.size.sum</th>\n",
       "      <th>trade.order_count.mean</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40</td>\n",
       "      <td>3179</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30</td>\n",
       "      <td>1289</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25</td>\n",
       "      <td>2161</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22</td>\n",
       "      <td>1791</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>32751</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>52</td>\n",
       "      <td>3450</td>\n",
       "      <td>3.057692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>32753</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>28</td>\n",
       "      <td>4547</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>36</td>\n",
       "      <td>4250</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>32763</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>53</td>\n",
       "      <td>3217</td>\n",
       "      <td>2.150943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>32767</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>29</td>\n",
       "      <td>3679</td>\n",
       "      <td>2.413793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_id  trade.log_return.realized_volatility  \\\n",
       "0           5                              0.002006   \n",
       "1          11                              0.000901   \n",
       "2          16                              0.001961   \n",
       "3          31                              0.001561   \n",
       "4          62                              0.000871   \n",
       "...       ...                                   ...   \n",
       "3825    32751                              0.001519   \n",
       "3826    32753                              0.001411   \n",
       "3827    32758                              0.001521   \n",
       "3828    32763                              0.001794   \n",
       "3829    32767                              0.001197   \n",
       "\n",
       "      trade.seconds_in_bucket.count  trade.size.sum  trade.order_count.mean  \\\n",
       "0                                40            3179                2.750000   \n",
       "1                                30            1289                1.900000   \n",
       "2                                25            2161                2.720000   \n",
       "3                                15            1962                3.933333   \n",
       "4                                22            1791                4.045455   \n",
       "...                             ...             ...                     ...   \n",
       "3825                             52            3450                3.057692   \n",
       "3826                             28            4547                3.892857   \n",
       "3827                             36            4250                3.500000   \n",
       "3828                             53            3217                2.150943   \n",
       "3829                             29            3679                2.413793   \n",
       "\n",
       "      stock_id  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "3825         0  \n",
       "3826         0  \n",
       "3827         0  \n",
       "3828         0  \n",
       "3829         0  \n",
       "\n",
       "[3830 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_train_df = make_trade_feature(0, DataBlock.TRAIN)\n",
    "trade_train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e281cfe2",
   "metadata": {
    "papermill": {
     "duration": 0.028421,
     "end_time": "2022-01-23T02:26:41.480303",
     "exception": false,
     "start_time": "2022-01-23T02:26:41.451882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Nearest-Neighbor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aca7436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:41.555136Z",
     "iopub.status.busy": "2022-01-23T02:26:41.550462Z",
     "iopub.status.idle": "2022-01-23T02:26:41.557458Z",
     "shell.execute_reply": "2022-01-23T02:26:41.557058Z",
     "shell.execute_reply.started": "2022-01-19T11:20:58.104849Z"
    },
    "papermill": {
     "duration": 0.048663,
     "end_time": "2022-01-23T02:26:41.557564",
     "exception": false,
     "start_time": "2022-01-23T02:26:41.508901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_NEIGHBORS_MAX = 1 # 80\n",
    "\n",
    "class Neighbors:\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 pivot: pd.DataFrame, \n",
    "                 p: float, \n",
    "                 metric: str = 'minkowski', \n",
    "                 metric_params: Optional[Dict] = None, \n",
    "                 exclude_self: bool = False):\n",
    "        self.name = name\n",
    "        self.exclude_self = exclude_self\n",
    "        self.p = p\n",
    "        self.metric = metric\n",
    "        \n",
    "        if metric == 'random':\n",
    "            n_queries = len(pivot)\n",
    "            self.neighbors = np.random.randint(n_queries, size=(n_queries, N_NEIGHBORS_MAX))\n",
    "        else:\n",
    "            print('metric ', metric)\n",
    "            \n",
    "            nn = NearestNeighbors(\n",
    "                n_neighbors=N_NEIGHBORS_MAX, \n",
    "                p=p, \n",
    "                metric=metric, \n",
    "                metric_params=metric_params\n",
    "            )\n",
    "           \n",
    "            nn.fit(pivot)\n",
    "            _, self.neighbors = nn.kneighbors(pivot, return_distance=True)\n",
    "\n",
    "        self.columns = self.index = self.feature_values = self.feature_col = None\n",
    "\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def make_nn_feature(self, n=5, agg=np.mean) -> pd.DataFrame:\n",
    "        assert self.feature_values is not None, \"should call rearrange_feature_values beforehand\"\n",
    "\n",
    "        start = 1 if self.exclude_self else 0\n",
    "\n",
    "        pivot_aggs = pd.DataFrame(\n",
    "            agg(self.feature_values[start:n,:,:], axis=0), \n",
    "            columns=self.columns, \n",
    "            index=self.index\n",
    "        )\n",
    "\n",
    "        dst = pivot_aggs.unstack().reset_index()\n",
    "        dst.columns = ['stock_id', 'time_id', f'{self.feature_col}_nn{n}_{self.name}_{agg.__name__}']\n",
    "        return dst\n",
    "\n",
    "\n",
    "class TimeIdNeighbors(Neighbors):\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        feature_pivot = df.pivot('time_id', 'stock_id', feature_col)\n",
    "        feature_pivot = feature_pivot.fillna(feature_pivot.mean())\n",
    "        feature_pivot.head()\n",
    "\n",
    "        feature_values = np.zeros((N_NEIGHBORS_MAX, *feature_pivot.shape))\n",
    "\n",
    "        for i in range(N_NEIGHBORS_MAX):\n",
    "            feature_values[i, :, :] += feature_pivot.values[self.neighbors[:, i], :]\n",
    "\n",
    "        self.columns = list(feature_pivot.columns)\n",
    "        self.index = list(feature_pivot.index)\n",
    "        self.feature_values = feature_values\n",
    "        self.feature_col = feature_col\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"time-id NN (name={self.name}, metric={self.metric}, p={self.p})\"\n",
    "\n",
    "\n",
    "class StockIdNeighbors(Neighbors):\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        \"\"\"stock-id based nearest neighbor features\"\"\"\n",
    "        feature_pivot = df.pivot('time_id', 'stock_id', feature_col)\n",
    "        feature_pivot = feature_pivot.fillna(feature_pivot.mean())\n",
    "\n",
    "        feature_values = np.zeros((N_NEIGHBORS_MAX, *feature_pivot.shape))\n",
    "\n",
    "        for i in range(N_NEIGHBORS_MAX):\n",
    "            feature_values[i, :, :] += feature_pivot.values[:, self.neighbors[:, i]]\n",
    "\n",
    "        self.columns = list(feature_pivot.columns)\n",
    "        self.index = list(feature_pivot.index)\n",
    "        self.feature_values = feature_values\n",
    "        self.feature_col = feature_col\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"stock-id NN (name={self.name}, metric={self.metric}, p={self.p})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "972a076e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:41.619972Z",
     "iopub.status.busy": "2022-01-23T02:26:41.619012Z",
     "iopub.status.idle": "2022-01-23T02:26:41.982083Z",
     "shell.execute_reply": "2022-01-23T02:26:41.981564Z",
     "shell.execute_reply.started": "2022-01-19T11:20:58.127333Z"
    },
    "papermill": {
     "duration": 0.395558,
     "end_time": "2022-01-23T02:26:41.982243",
     "exception": false,
     "start_time": "2022-01-23T02:26:41.586685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add_tau_features\n",
    "# the tau itself is meaningless for GBDT, but useful as input to aggregate in Nearest Neighbor features\n",
    "def add_tau_features(df_tau):\n",
    "    df_tau['trade.tau'] = np.sqrt(1 / df_tau['trade.seconds_in_bucket.count'])\n",
    "    df_tau['trade_150.tau'] = np.sqrt(1 / df_tau['trade_150.seconds_in_bucket.count'])\n",
    "    df_tau['book.tau'] = np.sqrt(1 / df_tau['book.seconds_in_bucket.count'])\n",
    "    df_tau['real_price'] = 0.01 / df_tau['tick_size']\n",
    "\n",
    "    return df_tau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be5a6240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T02:18:50.195022Z",
     "iopub.status.busy": "2022-01-16T02:18:50.1946Z",
     "iopub.status.idle": "2022-01-16T02:18:50.201136Z",
     "shell.execute_reply": "2022-01-16T02:18:50.199965Z",
     "shell.execute_reply.started": "2022-01-16T02:18:50.194964Z"
    },
    "papermill": {
     "duration": 0.030837,
     "end_time": "2022-01-23T02:26:42.050294",
     "exception": false,
     "start_time": "2022-01-23T02:26:42.019457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Build Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64aead97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:42.123778Z",
     "iopub.status.busy": "2022-01-23T02:26:42.122544Z",
     "iopub.status.idle": "2022-01-23T02:33:32.953387Z",
     "shell.execute_reply": "2022-01-23T02:33:32.953798Z",
     "shell.execute_reply.started": "2022-01-19T11:20:58.499414Z"
    },
    "papermill": {
     "duration": 410.874751,
     "end_time": "2022-01-23T02:33:32.953989",
     "exception": false,
     "start_time": "2022-01-23T02:26:42.079238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build_nearest_neighbors\n",
    "def build_nearest_neighbors(df_nn, \n",
    "    use_price_nn_features, \n",
    "    use_volume_nn_features, \n",
    "    use_size_nn_features, \n",
    "    use_random_nn_features):\n",
    "    time_id_neighbors: List[Neighbors] = []\n",
    "    stock_id_neighbors: List[Neighbors] = []\n",
    "\n",
    "    with timer('knn fit'):\n",
    "        df_pv = df_nn[['stock_id', 'time_id']].copy()\n",
    "        df_pv['price'] = 0.01 / df_nn['tick_size']\n",
    "        df_pv['vol'] = df_nn['book.log_return1.realized_volatility']\n",
    "        df_pv['trade.tau'] = df_nn['trade.tau']\n",
    "        df_pv['trade.size.sum'] = df_nn['book.total_volume.sum']\n",
    "\n",
    "        print('USE_PRICE_NN_FEATURES ', use_price_nn_features)\n",
    "        if use_price_nn_features:\n",
    "            pivot = df_pv.pivot('time_id', 'stock_id', 'price')\n",
    "            pivot = pivot.fillna(pivot.mean())\n",
    "            pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(\n",
    "                    'time_price_c', \n",
    "                    pivot, \n",
    "                    p=2, \n",
    "                    metric='canberra', \n",
    "                    exclude_self=True\n",
    "                )\n",
    "            )\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(\n",
    "                    'time_price_m', \n",
    "                    pivot, \n",
    "                    p=2, \n",
    "                    metric='mahalanobis',\n",
    "                    metric_params={'VI':np.linalg.inv(np.cov(pivot.values.T))}\n",
    "                )\n",
    "            )\n",
    "            stock_id_neighbors.append(\n",
    "                StockIdNeighbors(\n",
    "                    'stock_price_l1', \n",
    "                    minmax_scale(pivot.transpose()), \n",
    "                    p=1, \n",
    "                    exclude_self=True)\n",
    "            )\n",
    "\n",
    "        print('USE_VOL_NN_FEATURES ', use_volume_nn_features)\n",
    "        if use_volume_nn_features:\n",
    "            pivot = df_pv.pivot('time_id', 'stock_id', 'vol')\n",
    "            pivot = pivot.fillna(pivot.mean())\n",
    "            pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors('time_vol_l1', pivot, p=1)\n",
    "            )\n",
    "            stock_id_neighbors.append(\n",
    "                StockIdNeighbors(\n",
    "                    'stock_vol_l1', \n",
    "                    minmax_scale(pivot.transpose()), \n",
    "                    p=1, \n",
    "                    exclude_self=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print('USE_SIZE_NN_FEATURES ', use_size_nn_features)\n",
    "        if use_size_nn_features:\n",
    "            pivot = df_pv.pivot('time_id', 'stock_id', 'trade.size.sum')\n",
    "            pivot = pivot.fillna(pivot.mean())\n",
    "            pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(\n",
    "                    'time_size_m', \n",
    "                    pivot, \n",
    "                    p=2, \n",
    "                    metric='mahalanobis', \n",
    "                    # metric_params={'V':np.cov(pivot.values.T)}\n",
    "                    metric_params={'VI':np.linalg.inv(np.cov(pivot.values.T))}\n",
    "                )\n",
    "            )\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(\n",
    "                    'time_size_c', \n",
    "                    pivot, \n",
    "                    p=2, \n",
    "                    metric='canberra'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        print('USE_RANDOM_NN_FEATURES ', use_random_nn_features)\n",
    "        if use_random_nn_features:\n",
    "            pivot = df_pv.pivot('time_id', 'stock_id', 'vol')\n",
    "            pivot = pivot.fillna(pivot.mean())\n",
    "            pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(\n",
    "                    'time_random', \n",
    "                    pivot, \n",
    "                    p=2, \n",
    "                    metric='random'\n",
    "                )\n",
    "            )\n",
    "            stock_id_neighbors.append(\n",
    "                StockIdNeighbors(\n",
    "                    'stock_random', \n",
    "                    pivot.transpose(), \n",
    "                    p=2,\n",
    "                    metric='random')\n",
    "            )\n",
    "            \n",
    "    return time_id_neighbors, stock_id_neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27029360",
   "metadata": {
    "papermill": {
     "duration": 0.028479,
     "end_time": "2022-01-23T02:33:33.011086",
     "exception": false,
     "start_time": "2022-01-23T02:33:32.982607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Check Neighbor Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65fd5a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.073803Z",
     "iopub.status.busy": "2022-01-23T02:33:33.073080Z",
     "iopub.status.idle": "2022-01-23T02:33:33.075920Z",
     "shell.execute_reply": "2022-01-23T02:33:33.075471Z",
     "shell.execute_reply.started": "2022-01-19T11:27:55.548287Z"
    },
    "papermill": {
     "duration": 0.035942,
     "end_time": "2022-01-23T02:33:33.076032",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.040090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate_rank_correraltion\n",
    "def calculate_rank_correraltion(neighbors, top_n=5):\n",
    "    if not neighbors:\n",
    "        return\n",
    "    neighbor_indices = pd.DataFrame()\n",
    "    for n in neighbors:\n",
    "        neighbor_indices[n.name] = n.neighbors[:,:top_n].flatten()\n",
    "\n",
    "    sns.heatmap(neighbor_indices.corr('kendall'), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5123638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.138908Z",
     "iopub.status.busy": "2022-01-23T02:33:33.138122Z",
     "iopub.status.idle": "2022-01-23T02:33:33.192860Z",
     "shell.execute_reply": "2022-01-23T02:33:33.192422Z",
     "shell.execute_reply.started": "2022-01-19T11:27:55.555683Z"
    },
    "papermill": {
     "duration": 0.08837,
     "end_time": "2022-01-23T02:33:33.192975",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.104605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display_neighbors\n",
    "def display_neighbors(df_neighbor, neighbors_to_display, column_name, number_of_neighbor):\n",
    "    ids = np.array(sorted(df_neighbor[column_name].unique()))\n",
    "    for neighbor in neighbors_to_display:\n",
    "        print(neighbor)\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                ids[neighbor.neighbors[:,:number_of_neighbor]], \n",
    "                index=pd.Index(ids, name=column_name), \n",
    "                # ALERT: NOTE value was 10 in range and was updated to 2\n",
    "                columns=[f'top_{i+1}' for i in range(number_of_neighbor)] #10\n",
    "            ).iloc[1:6]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68bfd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_neighbors(df, time_id_neighbors, 'time_id', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7276b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_neighbors(df, stock_id_neighbors, 'stock_id', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2589b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.263643Z",
     "iopub.status.busy": "2022-01-23T02:33:33.262935Z",
     "iopub.status.idle": "2022-01-23T02:33:33.276604Z",
     "shell.execute_reply": "2022-01-23T02:33:33.276173Z",
     "shell.execute_reply.started": "2022-01-19T11:39:40.610534Z"
    },
    "papermill": {
     "duration": 0.051151,
     "end_time": "2022-01-23T02:33:33.276704",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.225553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# stock_ids = np.array(sorted(df['stock_id'].unique()))\n",
    "# for neighbor in stock_id_neighbors:\n",
    "#     print(neighbor)\n",
    "#     display(\n",
    "#         pd.DataFrame(\n",
    "#             stock_ids[neighbor.neighbors[:,:10]], \n",
    "#             index=pd.Index(stock_ids, name='stock_id'), \n",
    "#             # NOTE: range was 10,\n",
    "#             columns=[f'top_{i+1}' for i in range(10)] #10\n",
    "#         ).loc[0] #64\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e10b5471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.348457Z",
     "iopub.status.busy": "2022-01-23T02:33:33.347681Z",
     "iopub.status.idle": "2022-01-23T02:33:33.901994Z",
     "shell.execute_reply": "2022-01-23T02:33:33.902453Z",
     "shell.execute_reply.started": "2022-01-18T14:13:43.542166Z"
    },
    "papermill": {
     "duration": 0.591893,
     "end_time": "2022-01-23T02:33:33.902600",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.310707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate_rank_correraltion(time_id_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35df3e42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:34.038369Z",
     "iopub.status.busy": "2022-01-23T02:33:34.037754Z",
     "iopub.status.idle": "2022-01-23T02:33:34.275994Z",
     "shell.execute_reply": "2022-01-23T02:33:34.276373Z",
     "shell.execute_reply.started": "2022-01-18T14:13:43.949648Z"
    },
    "papermill": {
     "duration": 0.313195,
     "end_time": "2022-01-23T02:33:34.276516",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.963321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate_rank_correraltion(stock_id_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac11498c",
   "metadata": {
    "papermill": {
     "duration": 0.035477,
     "end_time": "2022-01-23T02:33:34.347529",
     "exception": false,
     "start_time": "2022-01-23T02:33:34.312052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Aggregate Features With Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec957b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:34.427036Z",
     "iopub.status.busy": "2022-01-23T02:33:34.426197Z",
     "iopub.status.idle": "2022-01-23T02:33:36.057149Z",
     "shell.execute_reply": "2022-01-23T02:33:36.056625Z",
     "shell.execute_reply.started": "2022-01-18T14:13:44.189634Z"
    },
    "papermill": {
     "duration": 1.674163,
     "end_time": "2022-01-23T02:33:36.057283",
     "exception": false,
     "start_time": "2022-01-23T02:33:34.383120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aggregate_features_with_neighbors\n",
    "# features with large changes over time are converted to relative ranks within time-id\n",
    "def aggregate_features_with_neighbors(df_agg):\n",
    "    df_agg['trade.order_count.mean'] = df_agg.groupby('time_id', group_keys=False)['trade.order_count.mean'].rank()\n",
    "    df_agg['book.total_volume.sum']  = df_agg.groupby('time_id', group_keys=False)['book.total_volume.sum'].rank()\n",
    "    df_agg['book.total_volume.mean'] = df_agg.groupby('time_id', group_keys=False)['book.total_volume.mean'].rank()\n",
    "    df_agg['book.total_volume.std']  = df_agg.groupby('time_id')['book.total_volume.std'].rank()\n",
    "\n",
    "    df_agg['trade.tau'] = df_agg.groupby('time_id', group_keys=False)['trade.tau'].rank()\n",
    "\n",
    "    for dt in [150, 300, 450]:\n",
    "        df_agg[f'book_{dt}.total_volume.sum']  = df_agg.groupby('time_id', group_keys=False)[f'book_{dt}.total_volume.sum'].rank()\n",
    "        df_agg[f'book_{dt}.total_volume.mean'] = df_agg.groupby('time_id', group_keys=False)[f'book_{dt}.total_volume.mean'].rank()\n",
    "        df_agg[f'book_{dt}.total_volume.std']  = df_agg.groupby('time_id', group_keys=False)[f'book_{dt}.total_volume.std'].rank()\n",
    "        df_agg[f'trade_{dt}.order_count.mean'] = df_agg.groupby('time_id', group_keys=False)[f'trade_{dt}.order_count.mean'].rank()\n",
    "\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6efc7d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:36.151666Z",
     "iopub.status.busy": "2022-01-23T02:33:36.150004Z",
     "iopub.status.idle": "2022-01-23T02:33:36.152354Z",
     "shell.execute_reply": "2022-01-23T02:33:36.152748Z",
     "shell.execute_reply.started": "2022-01-18T14:13:44.199422Z"
    },
    "papermill": {
     "duration": 0.059468,
     "end_time": "2022-01-23T02:33:36.152899",
     "exception": false,
     "start_time": "2022-01-23T02:33:36.093431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make_nearest_neighbor_feature\n",
    "def make_nearest_neighbor_feature(df_nn: pd.DataFrame, time_id_neighbors, stock_id_neighbors) -> pd.DataFrame:\n",
    "    df_nnf = df_nn.copy()\n",
    "\n",
    "    feature_cols_stock = {\n",
    "        'book.log_return1.realized_volatility': [np.mean, np.min, np.max, np.std],\n",
    "        'trade.seconds_in_bucket.count': [np.mean],\n",
    "        'trade.tau': [np.mean],\n",
    "        'trade_150.tau': [np.mean],\n",
    "        'book.tau': [np.mean],\n",
    "        'trade.size.sum': [np.mean],\n",
    "        'book.seconds_in_bucket.count': [np.mean],\n",
    "    }\n",
    "    \n",
    "    feature_cols = {\n",
    "        'book.log_return1.realized_volatility': [np.mean, np.min, np.max, np.std],\n",
    "        'real_price': [np.max, np.mean, np.min],\n",
    "        'trade.seconds_in_bucket.count': [np.mean],\n",
    "        'trade.tau': [np.mean],\n",
    "        'trade.size.sum': [np.mean],\n",
    "        'book.seconds_in_bucket.count': [np.mean],\n",
    "        'trade_150.tau_nn20_stock_vol_l1_mean': [np.mean],\n",
    "        'trade.size.sum_nn20_stock_vol_l1_mean': [np.mean],\n",
    "    }\n",
    "\n",
    "    time_id_neigbor_sizes = [3, 5, 10, 20, 40]\n",
    "    time_id_neigbor_sizes_vol = [2, 3, 5, 10, 20, 40]\n",
    "    stock_id_neighbor_sizes = [10, 20, 40]\n",
    "\n",
    "    ndf: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def _add_ndf(ndf: Optional[pd.DataFrame], dst: pd.DataFrame) -> pd.DataFrame:\n",
    "        if ndf is None:\n",
    "            return dst\n",
    "        else:\n",
    "            ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
    "            return ndf\n",
    "\n",
    "    # neighbor stock_id\n",
    "    for feature_col in feature_cols_stock.keys():\n",
    "        try:\n",
    "            if feature_col not in df_nnf.columns:\n",
    "                print(f\"column {feature_col} is skipped\")\n",
    "                continue\n",
    "\n",
    "            if not stock_id_neighbors:\n",
    "                continue\n",
    "\n",
    "            for nn in stock_id_neighbors:\n",
    "                nn.rearrange_feature_values(df_nnf, feature_col)\n",
    "\n",
    "            for agg in feature_cols_stock[feature_col]:\n",
    "                for n in stock_id_neighbor_sizes:\n",
    "                    try:\n",
    "                        for nn in stock_id_neighbors:\n",
    "                            dst = nn.make_nn_feature(n, agg)\n",
    "                            ndf = _add_ndf(ndf, dst)\n",
    "                    except Exception:\n",
    "                        print_trace('stock-id nn')\n",
    "                        pass\n",
    "        except Exception:\n",
    "            print_trace('stock-id nn')\n",
    "            pass\n",
    "\n",
    "    if ndf is not None:\n",
    "        df_nnf = pd.merge(df_nnf, ndf, on=['time_id', 'stock_id'], how='left')\n",
    "    ndf = None\n",
    "\n",
    "    # neighbor time_id\n",
    "    for feature_col in feature_cols.keys():\n",
    "        try:\n",
    "            if feature_col == 'real_price':\n",
    "                continue\n",
    "            if feature_col not in df_nnf.columns:\n",
    "                print(f\"column {feature_col} is skipped\")\n",
    "                continue\n",
    "\n",
    "            for nn in time_id_neighbors:\n",
    "                nn.rearrange_feature_values(df_nnf, feature_col)\n",
    "\n",
    "            if 'volatility' in feature_col:\n",
    "                time_id_ns = time_id_neigbor_sizes_vol\n",
    "            else:\n",
    "                time_id_ns = time_id_neigbor_sizes\n",
    "\n",
    "            for agg in feature_cols[feature_col]:\n",
    "                for n in time_id_ns:\n",
    "                    try:\n",
    "                        for nn in time_id_neighbors:\n",
    "                            dst = nn.make_nn_feature(n, agg)\n",
    "                            ndf = _add_ndf(ndf, dst)\n",
    "                    except Exception:\n",
    "                        print_trace('time-id nn')\n",
    "                        pass\n",
    "        except Exception:\n",
    "            print_trace('time-id nn')\n",
    "\n",
    "    if ndf is not None:\n",
    "        df_nnf = pd.merge(df_nnf, ndf, on=['time_id', 'stock_id'], how='left')\n",
    "\n",
    "    # features further derived from nearest neighbor features\n",
    "    try:\n",
    "        for sz in time_id_neigbor_sizes:\n",
    "            denominator = f\"real_price_nn{sz}_time_price_c\"\n",
    "\n",
    "            df_nnf[f'real_price_rankmin_{sz}']  = df_nnf['real_price'] / df2[f\"{denominator}_amin\"]\n",
    "            df_nnf[f'real_price_rankmax_{sz}']  = df_nnf['real_price'] / df2[f\"{denominator}_amax\"]\n",
    "            df_nnf[f'real_price_rankmean_{sz}'] = df_nnf['real_price'] / df2[f\"{denominator}_mean\"]\n",
    "\n",
    "        for sz in time_id_neigbor_sizes_vol:\n",
    "            denominator = f\"book.log_return1.realized_volatility_nn{sz}_time_price_c\"\n",
    "\n",
    "            df_nnf[f'vol_rankmin_{sz}'] = \\\n",
    "                df_nnf['book.log_return1.realized_volatility'] / df_nnf[f\"{denominator}_amin\"]\n",
    "            df_nnf[f'vol_rankmax_{sz}'] = \\\n",
    "                df_nnf['book.log_return1.realized_volatility'] / df_nnf[f\"{denominator}_amax\"]\n",
    "\n",
    "        price_cols = [c for c in df2.columns if 'real_price' in c and 'rank' not in c]\n",
    "        for c in price_cols:\n",
    "            del df_nnf[c]\n",
    "\n",
    "        for sz in time_id_neigbor_sizes_vol:\n",
    "            tgt = f'book.log_return1.realized_volatility_nn{sz}_time_price_m_mean'\n",
    "            df_nnf[f'{tgt}_rank'] = df_nnf.groupby('time_id', group_keys=False)[tgt].rank()\n",
    "    except Exception:\n",
    "        print_trace('nn features')\n",
    "\n",
    "    return df_nnf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "049e3ff0",
   "metadata": {
    "papermill": {
     "duration": 0.037563,
     "end_time": "2022-01-23T02:34:52.038355",
     "exception": false,
     "start_time": "2022-01-23T02:34:52.000792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Misc Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b672b203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:53.076612Z",
     "iopub.status.busy": "2022-01-23T02:34:53.075859Z",
     "iopub.status.idle": "2022-01-23T02:34:53.335135Z",
     "shell.execute_reply": "2022-01-23T02:34:53.334610Z",
     "shell.execute_reply.started": "2022-01-15T04:54:06.290787Z"
    },
    "papermill": {
     "duration": 1.258742,
     "end_time": "2022-01-23T02:34:53.335258",
     "exception": false,
     "start_time": "2022-01-23T02:34:52.076516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# skew correction for NN\n",
    "def skew_correction_for_nn(df_skew):\n",
    "    cols_to_log = [\n",
    "        'trade.size.sum',\n",
    "        'trade_150.size.sum',\n",
    "        'trade_300.size.sum',\n",
    "        'trade_450.size.sum',\n",
    "        'volume_imbalance'\n",
    "    ]\n",
    "    for c in df_skew.columns:\n",
    "        for check in cols_to_log:\n",
    "            try:\n",
    "                if check in c:\n",
    "                    df_skew[c] = np.log(df_skew[c]+1)\n",
    "                    break\n",
    "            except Exception:\n",
    "                print_trace('log1p')\n",
    "\n",
    "    return df_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76b80e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:53.415634Z",
     "iopub.status.busy": "2022-01-23T02:34:53.414883Z",
     "iopub.status.idle": "2022-01-23T02:34:54.757020Z",
     "shell.execute_reply": "2022-01-23T02:34:54.756480Z",
     "shell.execute_reply.started": "2022-01-15T04:54:06.724354Z"
    },
    "papermill": {
     "duration": 1.384579,
     "end_time": "2022-01-23T02:34:54.757155",
     "exception": false,
     "start_time": "2022-01-23T02:34:53.372576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rolling average of RV for similar trading volume\n",
    "def rolling_average_of_rv_for_similar_trading_volume(df_ra):\n",
    "    try:\n",
    "        df_ra.sort_values(by=['stock_id', 'book.total_volume.sum'], inplace=True)\n",
    "        df_ra.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        roll_target = 'book.log_return1.realized_volatility'\n",
    "\n",
    "        for window_size in [3, 10]:\n",
    "            df_ra[f'realized_volatility_roll{window_size}_by_book.total_volume.mean'] = \\\n",
    "                df_ra.groupby('stock_id', group_keys=False)[roll_target].rolling(window_size, center=True, min_periods=1) \\\n",
    "                                                    .mean() \\\n",
    "                                                    .reset_index() \\\n",
    "                                                    .sort_values(by=['level_1'])[roll_target].values\n",
    "    except Exception:\n",
    "        print_trace('mean RV')\n",
    "\n",
    "    return df_ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac17ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:54.865738Z",
     "iopub.status.busy": "2022-01-23T02:34:54.859008Z",
     "iopub.status.idle": "2022-01-23T02:34:57.630440Z",
     "shell.execute_reply": "2022-01-23T02:34:57.631709Z",
     "shell.execute_reply.started": "2022-01-15T04:54:08.318718Z"
    },
    "papermill": {
     "duration": 2.836215,
     "end_time": "2022-01-23T02:34:57.631962",
     "exception": false,
     "start_time": "2022-01-23T02:34:54.795747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # stock-id embedding (helps little)\n",
    "# try:\n",
    "#     lda_n = 3\n",
    "#     lda = LatentDirichletAllocation(n_components=lda_n, random_state=0)\n",
    "\n",
    "#     stock_id_emb = pd.DataFrame(\n",
    "#         lda.fit_transform(pivot.transpose()), \n",
    "#         index=df_pv.pivot('time_id', 'stock_id', 'vol').columns\n",
    "#     )\n",
    "\n",
    "#     for i in range(lda_n):\n",
    "#         df2[f'stock_id_emb{i}'] = df2['stock_id'].map(stock_id_emb[i])\n",
    "# except Exception:\n",
    "#     print_trace('LDA')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f898c5d1",
   "metadata": {
    "papermill": {
     "duration": 0.037142,
     "end_time": "2022-01-23T02:34:59.516263",
     "exception": false,
     "start_time": "2022-01-23T02:34:59.479121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reverse Engineering time-id Order & Make CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1306bfda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:59.616772Z",
     "iopub.status.busy": "2022-01-23T02:34:59.615063Z",
     "iopub.status.idle": "2022-01-23T02:34:59.617414Z",
     "shell.execute_reply": "2022-01-23T02:34:59.617868Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.7715Z"
    },
    "papermill": {
     "duration": 0.063706,
     "end_time": "2022-01-23T02:34:59.618003",
     "exception": false,
     "start_time": "2022-01-23T02:34:59.554297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reverse engineering time-id order\n",
    "%matplotlib inline\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    e = time.time() - s\n",
    "    print(f\"[{name}] {e:.3f}sec\")\n",
    "    \n",
    "def calc_price2(df):\n",
    "    tick = sorted(np.diff(sorted(np.unique(df.values.flatten()))))[0]\n",
    "    return 0.01 / tick\n",
    "\n",
    "def calc_prices(r):\n",
    "    df = pd.read_parquet(r.book_path, columns=['time_id', 'ask_price1', 'ask_price2', 'bid_price1', 'bid_price2'])\n",
    "    df = df.set_index('time_id')\n",
    "    df = df.groupby(level='time_id', group_keys=False).apply(calc_price2).to_frame('price').reset_index()\n",
    "    df['stock_id'] = r.stock_id\n",
    "    return df\n",
    "\n",
    "def sort_manifold(df, clf):\n",
    "    df_ = df.set_index('time_id')\n",
    "    df_ = pd.DataFrame(minmax_scale(df_.fillna(df_.mean())))\n",
    "\n",
    "    X_compoents = clf.fit_transform(df_)\n",
    "\n",
    "    dft = df.reindex(np.argsort(X_compoents[:,0])).reset_index(drop=True)\n",
    "    return np.argsort(X_compoents[:, 0]), X_compoents\n",
    "\n",
    "def reconstruct_time_id_order():\n",
    "    with timer('load files'):\n",
    "        book_path = DATA_DIR + '/optiver-realized-volatility-prediction/book_train.parquet/**/*.parquet'\n",
    "        print('book path ', book_path)\n",
    "        df_files = pd.DataFrame(\n",
    "            {'book_path': glob.glob(book_path)}) \\\n",
    "            .eval('stock_id = book_path.str.extract(\"stock_id=(\\d+)\").astype(\"int\")', engine='python')\n",
    "\n",
    "    with timer('calc prices'):\n",
    "        df_prices = pd.concat(Parallel(n_jobs=4, verbose=51)(delayed(calc_prices)(r) for _, r in df_files.iterrows()))\n",
    "        df_prices = df_prices.pivot('time_id', 'stock_id', 'price')\n",
    "        df_prices.columns = [f'stock_id={i}' for i in df_prices.columns]\n",
    "        df_prices = df_prices.reset_index(drop=False)\n",
    "\n",
    "    with timer('t-SNE(400) -> 50'):\n",
    "        clf = TSNE(n_components=1, perplexity=400, random_state=0, n_iter=2000)\n",
    "        order, X_compoents = sort_manifold(df_prices, clf)\n",
    "\n",
    "        clf = TSNE(n_components=1, perplexity=50, random_state=0, init=X_compoents, n_iter=2000, method='exact')\n",
    "        order, X_compoents = sort_manifold(df_prices, clf)\n",
    "\n",
    "        df_ordered = df_prices.reindex(order).reset_index(drop=True)\n",
    "        if df_ordered['stock_id=61'].iloc[0] > df_ordered['stock_id=61'].iloc[-1]:\n",
    "            df_ordered = df_ordered.reindex(df_ordered.index[::-1]).reset_index(drop=True)\n",
    "\n",
    "    # AMZN\n",
    "    # plt.plot(df_ordered['stock_id=61'])\n",
    "    \n",
    "    return df_ordered[['time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c3ad6b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:59.705424Z",
     "iopub.status.busy": "2022-01-23T02:34:59.704651Z",
     "iopub.status.idle": "2022-01-23T02:35:01.635920Z",
     "shell.execute_reply": "2022-01-23T02:35:01.636972Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.801275Z"
    },
    "papermill": {
     "duration": 1.981013,
     "end_time": "2022-01-23T02:35:01.637181",
     "exception": false,
     "start_time": "2022-01-23T02:34:59.656168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add_time_id_order\n",
    "def add_time_id_order(df_tid):\n",
    "    timeid_order = reconstruct_time_id_order()\n",
    "    timeid_order['time_id_order'] = np.arange(len(timeid_order))\n",
    "    df_tid['time_id_order'] = df_tid['time_id'].map(timeid_order.set_index('time_id')['time_id_order'])\n",
    "    df_tid = df_tid.sort_values(['time_id_order', 'stock_id']).reset_index(drop=True)\n",
    "    df_tid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b888bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek_null_columns\n",
    "def chek_null_columns(X):\n",
    "    xp = X.isna().any()\n",
    "    xp_null = xp.loc[lambda x : x == True]\n",
    "    nan_columns = list(xp_null.index)\n",
    "    print('Null columns ', nan_columns)\n",
    "    # X = X.drop(columns=nan_columns)\n",
    "    # return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ee88bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_time_id_ordered\n",
    "def plot_time_id_ordered(stock_id, df, first_n_records = None):\n",
    "    df_train_per_stock = df[df['stock_id'] == stock_id]\n",
    "    if first_n_records:\n",
    "        df_train_per_stock = df_train_per_stock[0: first_n_records]\n",
    "    print('df_train_per_stock.shape',df_train_per_stock.shape)\n",
    "    plt.plot(range(len(df_train_per_stock)), df_train_per_stock['target'])\n",
    "    plt.title('Time Id ordered plot of target')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Realized volatility')\n",
    "    plt.title('Reealized volatility for stock ' + str(stock_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e68994df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_time_id_ordered_plot(0, df_train, 36*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5adb5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_time_id_ordered_plot(0, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31e0e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1e3826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modal results operations \n",
    "def get_model_results_df():\n",
    "    return pd.DataFrame(model_results)\n",
    "\n",
    "def reset_model_results():\n",
    "    model_results = []\n",
    "\n",
    "def add_model_result(model_name, y_true, y_pred, isDart):\n",
    "    if isDart:\n",
    "        print('using dart metrics')\n",
    "        mae_value = mae(y_true, y_pred)\n",
    "        rmse_value = rmse(y_true, y_pred)\n",
    "        mse_value = mse(y_true, y_pred)\n",
    "        pass\n",
    "    else:\n",
    "        print('using sklearn metrics')\n",
    "        mse_value = mean_squared_error(y_true, y_pred)\n",
    "        rmse_value = mean_squared_error(y_true, y_pred, squared=False)\n",
    "        mae_value = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    model_result_light_gbm = [m for m in model_results if m['model_name'] == model_name]\n",
    "    if model_result_light_gbm:\n",
    "        print('value already exists in model results. So updating it')\n",
    "        for model in model_results:\n",
    "            if model['model_name'] == model_name:\n",
    "                model['mse'] = mse_value\n",
    "                model['mae'] = mae_value\n",
    "                model['rmse'] = rmse_value\n",
    "                model['added_date'] = datetime.now()\n",
    "    else:\n",
    "        print('adding new model results in')\n",
    "        model_results.append({'model_name': model_name, 'mse': mse_value, 'rmse': rmse_value, 'mae': mae_value, 'added_date': datetime.now()})\n",
    "\n",
    "    return model_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "020eecf0",
   "metadata": {
    "papermill": {
     "duration": 0.067715,
     "end_time": "2022-01-23T02:35:01.777174",
     "exception": false,
     "start_time": "2022-01-23T02:35:01.709459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LightGBM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36f6f703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:35:01.921148Z",
     "iopub.status.busy": "2022-01-23T02:35:01.920367Z",
     "iopub.status.idle": "2022-01-23T02:35:01.933964Z",
     "shell.execute_reply": "2022-01-23T02:35:01.934928Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.902446Z"
    },
    "papermill": {
     "duration": 0.091675,
     "end_time": "2022-01-23T02:35:01.935102",
     "exception": false,
     "start_time": "2022-01-23T02:35:01.843427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# light gbm\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def feval_RMSPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n",
    "\n",
    "# from: https://blog.amedama.jp/entry/lightgbm-cv-feature-importance\n",
    "def plot_importance(cvbooster, figsize=(10, 10)):\n",
    "    raw_importances = cvbooster.feature_importance(importance_type='gain')\n",
    "    feature_name = cvbooster.boosters[0].feature_name()\n",
    "    importance_df = pd.DataFrame(data=raw_importances,\n",
    "                                 columns=feature_name)\n",
    "    # order by average importance across folds\n",
    "    sorted_indices = importance_df.mean(axis=0).sort_values(ascending=False).index\n",
    "    sorted_importance_df = importance_df.loc[:, sorted_indices]\n",
    "    # plot top-n\n",
    "    PLOT_TOP_N = 50\n",
    "    plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]\n",
    "    _, ax = plt.subplots(figsize=figsize)\n",
    "    ax.grid()\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Feature')\n",
    "    ax.set_xlabel('Importance')\n",
    "    sns.boxplot(data=sorted_importance_df[plot_cols],\n",
    "                orient='h',\n",
    "                ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "def get_X(df_src):\n",
    "    cols = [c for c in df_src.columns if c not in ['time_id', 'target', 'tick_size']]\n",
    "    return df_src[cols]\n",
    "\n",
    "class EnsembleModel:\n",
    "    def __init__(self, models: List[lgb.Booster], weights: Optional[List[float]] = None):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "\n",
    "        features = list(self.models[0].feature_name())\n",
    "\n",
    "        for m in self.models[1:]:\n",
    "            assert features == list(m.feature_name())\n",
    "\n",
    "    def predict(self, x):\n",
    "        predicted = np.zeros((len(x), len(self.models)))\n",
    "\n",
    "        for i, m in enumerate(self.models):\n",
    "            w = self.weights[i] if self.weights is not None else 1\n",
    "            predicted[:, i] = w * m.predict(x)\n",
    "\n",
    "        ttl = np.sum(self.weights) if self.weights is not None else len(self.models)\n",
    "        return np.sum(predicted, axis=1) / ttl\n",
    "\n",
    "    def feature_name(self) -> List[str]:\n",
    "        return self.models[0].feature_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0afb222a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:35:02.048565Z",
     "iopub.status.busy": "2022-01-23T02:35:02.044618Z",
     "iopub.status.idle": "2022-01-23T03:35:55.320275Z",
     "shell.execute_reply": "2022-01-23T03:35:55.319782Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.922483Z"
    },
    "papermill": {
     "duration": 3653.32245,
     "end_time": "2022-01-23T03:35:55.320410",
     "exception": false,
     "start_time": "2022-01-23T02:35:01.997960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add_results_from_light_gbm\n",
    "def add_results_from_light_gbm(X_train_lgbm, y_train_lgbm, X_val_lgbm, y_val_lgbm, lr=0.3):\n",
    "    params = {\n",
    "    'objective': 'regression',\n",
    "    'verbose': 0,\n",
    "    'metric': '',\n",
    "    'reg_alpha': 5,\n",
    "    'reg_lambda': 5,\n",
    "    'min_data_in_leaf': 1000,\n",
    "    'max_depth': -1,\n",
    "    'num_leaves': 128,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'learning_rate': lr\n",
    "    }\n",
    "\n",
    "    ds = lgb.Dataset(X_train_lgbm, y_train_lgbm, weight=1/np.power(y_train_lgbm, 2))\n",
    "\n",
    "    ret = lgb.cv(params, ds, num_boost_round=8000, \n",
    "                    feval=feval_RMSPE, \n",
    "                    stratified=False, \n",
    "                    return_cvbooster=True, \n",
    "                    verbose_eval=20,\n",
    "                    early_stopping_rounds=int(40*0.1/lr))\n",
    "\n",
    "    # print(f\"# overall RMSPE: {ret['RMSPE-mean'][-1]}\")\n",
    "\n",
    "    best_iteration = len(ret['RMSPE-mean'])\n",
    "\n",
    "    # print('boosters length ', len(ret['cvbooster'].boosters))\n",
    "\n",
    "    best_mae = None\n",
    "    best_y_pred = None\n",
    "\n",
    "    for i in range(len(ret['cvbooster'].boosters)):\n",
    "        y_pred = ret['cvbooster'].boosters[i].predict(X_val_lgbm, num_iteration=best_iteration)\n",
    "        mae_value = mean_absolute_error(y_val_lgbm, y_pred)\n",
    "        if best_mae == None:\n",
    "            best_mae = mae_value\n",
    "\n",
    "        if mae_value < best_mae:\n",
    "            print('updating best mae value')\n",
    "            best_mae = mae_value\n",
    "            best_y_pred = y_pred\n",
    "        \n",
    "    print(add_model_result('LightGBM', y_val_lgbm, best_y_pred, False))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fbd4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importance(ret['cvbooster'], figsize=(10, 20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb015e20",
   "metadata": {
    "papermill": {
     "duration": 0.057064,
     "end_time": "2022-01-23T03:35:55.434906",
     "exception": false,
     "start_time": "2022-01-23T03:35:55.377842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dce13e5",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-23T03:35:55.569557Z",
     "iopub.status.busy": "2022-01-23T03:35:55.558558Z",
     "iopub.status.idle": "2022-01-23T03:35:56.706846Z",
     "shell.execute_reply": "2022-01-23T03:35:56.705908Z",
     "shell.execute_reply.started": "2022-01-15T04:57:16.2193Z"
    },
    "papermill": {
     "duration": 1.211778,
     "end_time": "2022-01-23T03:35:56.706992",
     "exception": false,
     "start_time": "2022-01-23T03:35:55.495214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NN Training\n",
    "\n",
    "NUM_WORKERS = 0 #4\n",
    "\n",
    "null_check_cols = [\n",
    "    'book.log_return1.realized_volatility',\n",
    "    'book_150.log_return1.realized_volatility',\n",
    "    'book_300.log_return1.realized_volatility',\n",
    "    'book_450.log_return1.realized_volatility',\n",
    "    'trade.log_return.realized_volatility',\n",
    "    'trade_150.log_return.realized_volatility',\n",
    "    'trade_300.log_return.realized_volatility',\n",
    "    'trade_450.log_return.realized_volatility'\n",
    "]\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def rmspe_metric(y_true, y_pred):\n",
    "    rmspe = np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_loss(y_true, y_pred):\n",
    "    rmspe = torch.sqrt(torch.mean(torch.square((y_true - y_pred) / y_true)))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "class RMSPE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"rmspe\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        return np.sqrt(np.mean(np.square((y_true - y_score) / y_true)))\n",
    "\n",
    "def RMSPELoss_Tabnet(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 )).clone()\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num: np.ndarray, y: Optional[np.ndarray]):\n",
    "        super().__init__()\n",
    "        self.x_num = x_num\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x_num[idx]\n",
    "        else:\n",
    "            return self.x_num[idx], self.y[idx]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_num_dim: int,\n",
    "                 dropout: float = 0.0,\n",
    "                 hidden: int = 50,\n",
    "                 bn: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        if bn:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_num):\n",
    "        x = self.sequence(x_num)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_features: int,\n",
    "                 hidden_size: int,\n",
    "                 emb_dim: int = 10,\n",
    "                 dropout_cat: float = 0.2,\n",
    "                 channel_1: int = 256,\n",
    "                 channel_2: int = 512,\n",
    "                 channel_3: int = 512,\n",
    "                 dropout_top: float = 0.1,\n",
    "                 dropout_mid: float = 0.3,\n",
    "                 dropout_bottom: float = 0.2,\n",
    "                 weight_norm: bool = True,\n",
    "                 two_stage: bool = True,\n",
    "                 celu: bool = True,\n",
    "                 kernel1: int = 5,\n",
    "                 leaky_relu: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        num_targets = 1\n",
    "\n",
    "        cha_1_reshape = int(hidden_size / channel_1)\n",
    "        cha_po_1 = int(hidden_size / channel_1 / 2)\n",
    "        cha_po_2 = int(hidden_size / channel_1 / 2 / 2) * channel_3\n",
    "\n",
    "        self.cha_1 = channel_1\n",
    "        self.cha_2 = channel_2\n",
    "        self.cha_3 = channel_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "        self.two_stage = two_stage\n",
    "\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features),\n",
    "            nn.Dropout(dropout_top),\n",
    "            nn.utils.weight_norm(nn.Linear(num_features, hidden_size), dim=None),\n",
    "            nn.CELU(0.06) if celu else nn.ReLU()\n",
    "        )\n",
    "\n",
    "        def _norm(layer, dim=None):\n",
    "            return nn.utils.weight_norm(layer, dim=dim) if weight_norm else layer\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(channel_1),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_1, channel_2, kernel_size=kernel1, stride=1, padding=kernel1 // 2, bias=False)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(output_size=cha_po_1),\n",
    "            nn.BatchNorm1d(channel_2),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if self.two_stage:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_mid),\n",
    "                _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Conv1d(channel_2, channel_3, kernel_size=5, stride=1, padding=2, bias=True)),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        if leaky_relu:\n",
    "            self.dense = nn.Sequential(\n",
    "                nn.BatchNorm1d(cha_po_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Linear(cha_po_2, num_targets), dim=0),\n",
    "                nn.LeakyReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.dense = nn.Sequential(\n",
    "                nn.BatchNorm1d(cha_po_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Linear(cha_po_2, num_targets), dim=0)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_num):\n",
    "        x = self.expand(x_num)\n",
    "        x = x.reshape(x.shape[0], self.cha_1, self.cha_1_reshape)\n",
    "        x = self.conv1(x)\n",
    "        if self.two_stage:\n",
    "            x = self.conv2(x) * x\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "        x = self.flt(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "# def preprocess_nn(\n",
    "#         X: pd.DataFrame,\n",
    "#         scaler: Optional[StandardScaler] = None,\n",
    "#         scaler_type: str = 'standard',\n",
    "#         n_pca: int = -1,\n",
    "#         na_cols: bool = True):\n",
    "#     if na_cols:\n",
    "#         #for c in X.columns:\n",
    "#         for c in null_check_cols:\n",
    "#             if c in X.columns:\n",
    "#                 X[f\"{c}_isnull\"] = X[c].isnull().astype(int)\n",
    "\n",
    "#     cat_cols = [c for c in X.columns if c in ['time_id', 'stock_id']]\n",
    "#     num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "#     X_num = X[num_cols].values.astype(np.float32)\n",
    "#     X_cat = np.nan_to_num(X[cat_cols].values.astype(np.int32))\n",
    "\n",
    "#     def _pca(X_num_):\n",
    "#         if n_pca > 0:\n",
    "#             pca = PCA(n_components=n_pca, random_state=0)\n",
    "#             return pca.fit_transform(X_num)\n",
    "#         return X_num\n",
    "\n",
    "#     if scaler is None:\n",
    "#         scaler = StandardScaler()\n",
    "#         X_num = scaler.fit_transform(X_num)\n",
    "#         X_num = np.nan_to_num(X_num, posinf=0, neginf=0)\n",
    "#         return _pca(X_num), X_cat, cat_cols, scaler\n",
    "#     else:\n",
    "#         X_num = scaler.transform(X_num) #TODO: infでも大丈夫？\n",
    "#         X_num = np.nan_to_num(X_num, posinf=0, neginf=0)\n",
    "#         return _pca(X_num), X_cat, cat_cols\n",
    "\n",
    "\n",
    "def train_epoch(data_loader: DataLoader,\n",
    "                model: nn.Module,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                device,\n",
    "                clip_grad: float = 1.5):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    step = 0\n",
    "\n",
    "    for x_num, y in tqdm(data_loader, position=0, leave=True, desc='Training'):\n",
    "        batch_size = x_num.size(0)\n",
    "        x_num = x_num.to(device, dtype=torch.float)\n",
    "        y = y.to(device, dtype=torch.float)\n",
    "        loss = rmspe_loss(y, model(x_num))\n",
    "        losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def evaluate(data_loader: DataLoader, model, device):\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_num, y in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n",
    "            batch_size = x_num.size(0)\n",
    "            x_num = x_num.to(device, dtype=torch.float)\n",
    "            y = y.to(device, dtype=torch.float)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(x_num)\n",
    "\n",
    "            loss = rmspe_loss(y, output)\n",
    "            losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "\n",
    "            targets = y.detach().cpu().numpy()\n",
    "            output = output.detach().cpu().numpy()\n",
    "\n",
    "            final_targets.append(targets)\n",
    "            final_outputs.append(output)\n",
    "\n",
    "    final_targets = np.concatenate(final_targets)\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "\n",
    "    try:\n",
    "        metric = rmspe_metric(final_targets, final_outputs)\n",
    "    except:\n",
    "        metric = None\n",
    "\n",
    "    return final_outputs, final_targets, losses.avg, metric\n",
    "\n",
    "def predict_nn(X_df: pd.DataFrame,\n",
    "               model: Union[List[MLP], MLP],\n",
    "               device,\n",
    "               ensemble_method='mean'):\n",
    "    if not isinstance(model, list):\n",
    "        model = [model]\n",
    "\n",
    "    for m in model:\n",
    "        m.eval()\n",
    "\n",
    "    evaluation_dataset = TabularDataset(X_df.values, None)\n",
    "    evaluation_data_loader = torch.utils.data.DataLoader(evaluation_dataset,\n",
    "                                               batch_size=512,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=NUM_WORKERS)\n",
    "\n",
    "    final_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_num in tqdm(evaluation_data_loader, position=0, leave=True, desc='Evaluating'):\n",
    "            x_num = x_num.to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = []\n",
    "            with torch.no_grad():\n",
    "                for m in model:\n",
    "                    output = m(x_num)\n",
    "                    outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "            if ensemble_method == 'median':\n",
    "                pred = np.nanmedian(np.array(outputs), axis=0)\n",
    "            else:\n",
    "                pred = np.array(outputs).mean(axis=0)\n",
    "            final_outputs.append(pred)\n",
    "\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "    return final_outputs\n",
    "\n",
    "\n",
    "def train_nn(\n",
    "             X_train_df,\n",
    "             y_train_df,\n",
    "             X_val_df,\n",
    "             y_val_df,\n",
    "             device,\n",
    "             emb_dim: int = 25,\n",
    "             batch_size: int = 1024,\n",
    "             model_type: str = 'mlp',\n",
    "             mlp_dropout: float = 0.0,\n",
    "             mlp_hidden: int = 64,\n",
    "             mlp_bn: bool = False,\n",
    "             cnn_hidden: int = 64,\n",
    "             cnn_channel1: int = 32,\n",
    "             cnn_channel2: int = 32,\n",
    "             cnn_channel3: int = 32,\n",
    "             cnn_kernel1: int = 5,\n",
    "             cnn_celu: bool = False,\n",
    "             cnn_weight_norm: bool = False,\n",
    "             dropout_emb: bool = 0.0,\n",
    "             lr: float = 1e-3,\n",
    "             weight_decay: float = 0.0,\n",
    "             model_path: str = 'fold_{}.pth',\n",
    "             scaler_type: str = 'standard',\n",
    "             output_dir: str = 'artifacts',\n",
    "             scheduler_type: str = 'onecycle',\n",
    "             optimizer_type: str = 'adam',\n",
    "             max_lr: float = 0.01,\n",
    "             epochs: int = 30,\n",
    "             seed: int = 42,\n",
    "             n_pca: int = -1,\n",
    "             batch_double_freq: int = 50,\n",
    "             cnn_dropout: float = 0.1,\n",
    "             na_cols: bool = True,\n",
    "             cnn_leaky_relu: bool = False,\n",
    "             patience: int = 8,\n",
    "             factor: float = 0.5):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    best_losses = []\n",
    "    best_predictions = []\n",
    "\n",
    "    cur_batch = batch_size\n",
    "    best_loss = 1e10\n",
    "    best_prediction = None\n",
    "    train_dataset = TabularDataset(X_train_df.values, y_train_df.values)\n",
    "    valid_dataset = TabularDataset(X_val_df.values, y_val_df.values)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cur_batch, shuffle=False,\n",
    "                                                num_workers=NUM_WORKERS)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=cur_batch, shuffle=False,\n",
    "                                                num_workers=NUM_WORKERS)\n",
    "\n",
    "    if model_type == 'mlp':\n",
    "        model = MLP(X_train_df.shape[1],\n",
    "                    dropout=mlp_dropout, \n",
    "                    hidden=mlp_hidden, \n",
    "                    bn=mlp_bn)\n",
    "    elif model_type == 'cnn':\n",
    "        model = CNN(X_train_df.shape[1],\n",
    "                    hidden_size=cnn_hidden,\n",
    "                    emb_dim=emb_dim,\n",
    "                    dropout_cat=dropout_emb,\n",
    "                    channel_1=cnn_channel1,\n",
    "                    channel_2=cnn_channel2,\n",
    "                    channel_3=cnn_channel3,\n",
    "                    two_stage=False,\n",
    "                    kernel1=cnn_kernel1,\n",
    "                    celu=cnn_celu,\n",
    "                    dropout_top=cnn_dropout,\n",
    "                    dropout_mid=cnn_dropout,\n",
    "                    dropout_bottom=cnn_dropout,\n",
    "                    weight_norm=cnn_weight_norm,\n",
    "                    leaky_relu=cnn_leaky_relu)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    model = model.to(device)\n",
    "\n",
    "    if optimizer_type == 'adamw':\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_type == 'adam':\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    scheduler = epoch_scheduler = None\n",
    "    if scheduler_type == 'onecycle':\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=opt, pct_start=0.1, div_factor=1e3,\n",
    "                                                        max_lr=max_lr, epochs=epochs,\n",
    "                                                        steps_per_epoch=len(train_loader))\n",
    "    elif scheduler_type == 'reduce':\n",
    "        epoch_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt,\n",
    "                                                                        mode='min',\n",
    "                                                                        min_lr=1e-7,\n",
    "                                                                        patience=patience,\n",
    "                                                                        verbose=True,\n",
    "                                                                        factor=factor)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if epoch > 0 and epoch % batch_double_freq == 0:\n",
    "            cur_batch = cur_batch * 2\n",
    "            print(f'batch: {cur_batch}')\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                        batch_size=cur_batch,\n",
    "                                                        shuffle=False,\n",
    "                                                        num_workers=NUM_WORKERS)\n",
    "       \n",
    "        train_loss = train_epoch(train_loader, model, opt, scheduler, device)\n",
    "        predictions, valid_targets, valid_loss, rmspe = evaluate(valid_loader, model, device=device)\n",
    "        print(f\"epoch {epoch}, train loss: {train_loss:.3f}, valid rmspe: {rmspe:.3f}\")\n",
    "\n",
    "        if epoch_scheduler is not None:\n",
    "            epoch_scheduler.step(rmspe)\n",
    "\n",
    "        if rmspe < best_loss:\n",
    "            print(f'new best:{rmspe}')\n",
    "            best_loss = rmspe\n",
    "            best_prediction = predictions\n",
    "            model_save_path = DATA_DIR + \"/\" + os.path.join(output_dir, model_path.format(0))\n",
    "            torch.save(model, model_save_path)\n",
    "\n",
    "    best_predictions.append(best_prediction)\n",
    "    best_losses.append(best_loss)\n",
    "    # del model, train_dataset, valid_dataset, train_loader, valid_loader, X_tr, X_va, X_tr_cat, X_va_cat, y_tr, y_va, opt\n",
    "    del train_dataset, valid_dataset, train_loader, valid_loader, opt\n",
    "    if scheduler is not None:\n",
    "        del scheduler\n",
    "    gc.collect()\n",
    "    # , scaler\n",
    "    return model, best_losses, best_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c3cb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device mps\n"
     ]
    }
   ],
   "source": [
    "# get_device_name\n",
    "def get_device_name():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    \n",
    "    return \"cpu\"\n",
    "device = torch.device(get_device_name())\n",
    "print('device', device)\n",
    "\n",
    "# del df, df_train\n",
    "gc.collect()\n",
    "\n",
    "def get_top_n_models(models, scores, top_n):\n",
    "    if len(models) <= top_n:\n",
    "        print('number of models are less than top_n. all models will be used')\n",
    "        return models\n",
    "    sorted_ = [(y, x) for y, x in sorted(zip(scores, models), key=lambda pair: pair[0])]\n",
    "    print(f'scores(sorted): {[y for y, _ in sorted_]}')\n",
    "    return [x for _, x in sorted_][:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12245cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T03:35:57.029334Z",
     "iopub.status.busy": "2022-01-23T03:35:56.898214Z",
     "iopub.status.idle": "2022-01-23T06:56:27.693883Z",
     "shell.execute_reply": "2022-01-23T06:56:27.695021Z",
     "shell.execute_reply.started": "2022-01-15T04:57:17.584692Z"
    },
    "papermill": {
     "duration": 12030.930352,
     "end_time": "2022-01-23T06:56:27.695345",
     "exception": false,
     "start_time": "2022-01-23T03:35:56.764993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add_results_for_mlp\n",
    "def add_results_for_mlp(X_train_mlp, y_train_mlp, X_val_mlp, y_val_mlp, X_test_mlp, y_test_mlp, epochs, lr = 0.002):\n",
    "    model_mlp, nn_losses, nn_preds = train_nn(\n",
    "                                            X_train_mlp,\n",
    "                                            y_train_mlp,\n",
    "                                            X_val_mlp,\n",
    "                                            y_val_mlp,\n",
    "                                            device=device, \n",
    "                                            batch_size=512,\n",
    "                                            mlp_bn=True,\n",
    "                                            mlp_hidden=256,\n",
    "                                            mlp_dropout=0.0,\n",
    "                                            emb_dim=30,\n",
    "                                            epochs=epochs,\n",
    "                                            lr=lr,\n",
    "                                            max_lr=0.0055,\n",
    "                                            weight_decay=1e-7,\n",
    "                                            model_path='mlp_fold_{}' + f\"_seed{SEED}.pth\",\n",
    "                                            seed=0)\n",
    "\n",
    "    model_mlp_preds = predict_nn(X_test_mlp, model_mlp, device, ensemble_method=ENSEMBLE_METHOD)\n",
    "    add_model_result('MLP', y_test_mlp, model_mlp_preds, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da4acd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_results_for_cnn\n",
    "def add_results_for_cnn(X_train_cnn, y_train_cnn, X_val_cnn, y_val_cnn, X_test_cnn, y_test_cnn, epochs, lr = 0.00038):\n",
    "    model_cnn, nn_losses, nn_preds = train_nn(\n",
    "                                            X_train_cnn,\n",
    "                                            y_train_cnn,\n",
    "                                            X_val_cnn,\n",
    "                                            y_val_cnn,\n",
    "                                            device=device, \n",
    "                                            cnn_hidden=8*128,\n",
    "                                            batch_size=1280,\n",
    "                                            model_type='cnn',\n",
    "                                            emb_dim=30,\n",
    "                                            epochs=EPOCHS, #epochs,\n",
    "                                            cnn_channel1=128,\n",
    "                                            cnn_channel2=3*128,\n",
    "                                            cnn_channel3=3*128,\n",
    "                                            lr=lr, #0.0011,\n",
    "                                            max_lr=0.0013,\n",
    "                                            weight_decay=6.5e-6,\n",
    "                                            optimizer_type='adam',\n",
    "                                            scheduler_type='reduce',\n",
    "                                            model_path='cnn_fold_{}' + f\"_seed{SEED}.pth\",\n",
    "                                            seed=0,\n",
    "                                            cnn_dropout=0.0,\n",
    "                                            cnn_weight_norm=False, # Note: True\n",
    "                                            cnn_leaky_relu=False,\n",
    "                                            patience=8,\n",
    "                                            factor=0.3)\n",
    "\n",
    "    model_cnn_preds = predict_nn(X_test_cnn, model_cnn, device, ensemble_method=ENSEMBLE_METHOD)\n",
    "    add_model_result('CNN', y_test_cnn, model_cnn_preds, False)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "834277e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_timeseries_data\n",
    "def create_timeseries_data(df):\n",
    "    df_ts = TimeSeries.from_dataframe(df)\n",
    "    scaler = Scaler()\n",
    "    df_ts = scaler.fit_transform(df_ts).astype(np.float32)\n",
    "    print('Length of Timeseries ', len(df_ts))\n",
    "    return df_ts, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef939fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_results_for_TCN\n",
    "def add_results_for_TCN(X_train_ts_tcn, y_train_ts_tcn, X_val_ts_tcn, y_val_ts_tcn, X_test_ts_tcn, y_test_ts_tcn):\n",
    "    model_tcn = TCNModel(\n",
    "        input_chunk_length=72,\n",
    "        output_chunk_length=36,\n",
    "        n_epochs=EPOCHS, #500\n",
    "        dropout=0.1,\n",
    "        dilation_base=2,\n",
    "        weight_norm=True,\n",
    "        kernel_size=3,\n",
    "        num_filters=3,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    model_tcn.fit(\n",
    "        series=y_train_ts_tcn,\n",
    "        past_covariates=X_train_ts_tcn,\n",
    "        val_series=y_val_ts_tcn,\n",
    "        val_past_covariates=X_val_ts_tcn,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    backtest_tcn = model_tcn.historical_forecasts(\n",
    "        series=y_test_ts_tcn,\n",
    "        past_covariates=X_test_ts_tcn,\n",
    "        forecast_horizon=36,\n",
    "        retrain=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    add_model_result('TCN', y_test_ts_tcn, backtest_tcn, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9888c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_tcn_predictions\n",
    "def plot_tcn_predictions(y_test_ts_tcn, backtest_tcn):\n",
    "    y_test_ts_tcn.plot(label=\"actual\")\n",
    "    backtest_tcn.plot(label=\"backtest (H=6)\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e1a6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_results_for_lstm\n",
    "def add_results_for_lstm(X_train_ts_lstm, y_train_ts_lstm, X_val_ts_lstm, y_val_ts_lstm, X_test_ts_lstm, y_test_ts_lstm):\n",
    "    model_lstm = RNNModel(\n",
    "        model=\"LSTM\",\n",
    "        hidden_dim=20,\n",
    "        n_rnn_layers=2,\n",
    "        dropout=0.2,\n",
    "        batch_size=16,\n",
    "        n_epochs=EPOCHS,\n",
    "        optimizer_kwargs={\"lr\": 1e-3},\n",
    "        random_state=0,\n",
    "        training_length=300,\n",
    "        input_chunk_length=300,\n",
    "        likelihood=GaussianLikelihood(),\n",
    "    )\n",
    "\n",
    "    model_lstm.fit(\n",
    "        series=y_train_ts_lstm,\n",
    "        future_covariates=X_train_ts_lstm,\n",
    "        val_series=y_val_ts_lstm,\n",
    "        val_future_covariates=X_val_ts_lstm,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    backtest_lstm = model_lstm.historical_forecasts(\n",
    "        series=y_test_ts_lstm,\n",
    "        future_covariates=X_test_ts_lstm,\n",
    "        forecast_horizon=36,\n",
    "        retrain=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    add_model_result('LSTM', y_test_ts_lstm, backtest_lstm, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6b007a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_lstm_predictions\n",
    "def plot_lstm_predictions(y_test_ts_lstm, backtest_lstm):\n",
    "    y_test_ts_lstm.plot(label=\"actual\")\n",
    "    backtest_lstm.plot(label=\"backtest (H=6)\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bb97e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_results_for_transformer\n",
    "def add_results_for_transformer(X_train_ts_trans, y_train_ts_trans, X_val_ts_trans, y_val_ts_trans, X_test_ts_trans, y_test_ts_trans):\n",
    "    model_transformer = TransformerModel(\n",
    "        input_chunk_length=12,\n",
    "        output_chunk_length=1,\n",
    "        batch_size=32,\n",
    "        n_epochs=EPOCHS,\n",
    "        model_name=\"air_transformer\",\n",
    "        nr_epochs_val_period=10,\n",
    "        d_model=16,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=2,\n",
    "        num_decoder_layers=2,\n",
    "        dim_feedforward=128,\n",
    "        dropout=0.1,\n",
    "        activation=\"relu\",\n",
    "        random_state=42,\n",
    "        save_checkpoints=True,\n",
    "        force_reset=True,\n",
    "    )\n",
    "\n",
    "    model_transformer.fit(\n",
    "        series=y_train_ts_trans,\n",
    "        past_covariates=X_train_ts_trans,\n",
    "        val_series=y_val_ts_trans,\n",
    "        val_past_covariates=X_val_ts_trans,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    backtest_transformer = model_transformer.historical_forecasts(\n",
    "        series=y_test_ts_trans,\n",
    "        past_covariates=X_test_ts_trans,\n",
    "        forecast_horizon=36,\n",
    "        retrain=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    add_model_result('Transformer', y_test_ts_trans, backtest_transformer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a622cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform_experiments_multivariate\n",
    "def perform_experiments_multivariate(df_experiment):\n",
    "    df_train, df_validation, df_test = split_df_into_train_val_test(df_experiment)\n",
    "\n",
    "    # prepare train, validation and test data\n",
    "    X_train = get_X(df_train)\n",
    "    X_val = get_X(df_validation)\n",
    "    X_test = get_X(df_test)\n",
    "\n",
    "    y_train = df_train['target']\n",
    "    y_val = df_validation['target']\n",
    "    y_test = df_test['target']\n",
    "\n",
    "    X_train_ts, X_train_ts_scaler = create_timeseries_data(X_train)\n",
    "    X_val_ts, X_val_ts_scaler = create_timeseries_data(X_val)\n",
    "    X_test_ts, X_test_ts_scaler = create_timeseries_data(X_test)\n",
    "\n",
    "    y_train_ts, y_train_ts_scaler = create_timeseries_data(y_train.to_frame())\n",
    "    y_val_ts, y_val_ts_scaler = create_timeseries_data(y_val.to_frame())\n",
    "    y_test_ts, y_test_ts_scaler = create_timeseries_data(y_test.to_frame())\n",
    "\n",
    "    # X_ts = X_train_ts.append(X_val_ts)\n",
    "    # y_ts = y_train_ts.append(y_val_ts)\n",
    "\n",
    "    # models\n",
    "    reset_model_results()\n",
    "    add_results_from_light_gbm(X_train, y_train, X_val, y_val, lr=0.3)\n",
    "    add_results_for_mlp(X_train, y_train, X_val, y_val, X_test, y_test, EPOCHS, lr = 0.002)\n",
    "    add_results_for_cnn(X_train, y_train, X_val, y_val, X_test, y_test, EPOCHS, lr = 0.00038)\n",
    "    add_results_for_TCN(X_train_ts, y_train_ts, X_val_ts, y_val_ts, X_test_ts, y_test_ts)\n",
    "    add_results_for_lstm(X_train_ts, y_train_ts, X_val_ts, y_val_ts, X_test_ts, y_test_ts)\n",
    "    add_results_for_transformer(X_train_ts, y_train_ts, X_val_ts, y_val_ts, X_test_ts, y_test_ts)\n",
    "    \n",
    "    return get_model_results_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f956eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train.shape  (428932, 3)\n",
      "stock_ids  112\n",
      "Train.shape  (3830, 3)\n",
      "stock_ids  {0}\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', 'train.csv'))\n",
    "stock_ids = set(train['stock_id'])\n",
    "print('Train.shape ', train.shape)\n",
    "print('stock_ids ', len(stock_ids))\n",
    "\n",
    "stock_ids_to_include = [0]\n",
    "train = train[train['stock_id'].isin(stock_ids_to_include)]\n",
    "print('Train.shape ', train.shape)\n",
    "stock_ids = set(train['stock_id'])\n",
    "print('stock_ids ', stock_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "914aadf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[books] 5.067sec\n",
      "[trades] 0.747sec\n",
      "[extra features] 0.008sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>book.wap1.sum</th>\n",
       "      <th>book.wap2.sum</th>\n",
       "      <th>book.log_return1.realized_volatility</th>\n",
       "      <th>book.log_return2.realized_volatility</th>\n",
       "      <th>book.log_return_ask1.realized_volatility</th>\n",
       "      <th>book.log_return_ask2.realized_volatility</th>\n",
       "      <th>book.log_return_bid1.realized_volatility</th>\n",
       "      <th>book.log_return_bid2.realized_volatility</th>\n",
       "      <th>trade.log_return.realized_volatility</th>\n",
       "      <th>trade.seconds_in_bucket.count</th>\n",
       "      <th>trade.size.sum</th>\n",
       "      <th>trade.order_count.mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>303.125061</td>\n",
       "      <td>303.105539</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40</td>\n",
       "      <td>3179</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>200.047768</td>\n",
       "      <td>200.041171</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30</td>\n",
       "      <td>1289</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>187.913849</td>\n",
       "      <td>187.939824</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25</td>\n",
       "      <td>2161</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>119.859781</td>\n",
       "      <td>119.835941</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>175.932865</td>\n",
       "      <td>175.934256</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22</td>\n",
       "      <td>1791</td>\n",
       "      <td>4.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>296.387479</td>\n",
       "      <td>296.365481</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>52</td>\n",
       "      <td>3450</td>\n",
       "      <td>3.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>206.063903</td>\n",
       "      <td>206.100395</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>28</td>\n",
       "      <td>4547</td>\n",
       "      <td>3.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>187.915689</td>\n",
       "      <td>187.897700</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>36</td>\n",
       "      <td>4250</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>307.723687</td>\n",
       "      <td>307.732623</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>53</td>\n",
       "      <td>3217</td>\n",
       "      <td>2.150943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>227.800017</td>\n",
       "      <td>227.809904</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>29</td>\n",
       "      <td>3679</td>\n",
       "      <td>2.413793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock_id  time_id    target  book.wap1.sum  book.wap2.sum  \\\n",
       "0            0        5  0.004136     303.125061     303.105539   \n",
       "1            0       11  0.001445     200.047768     200.041171   \n",
       "2            0       16  0.002168     187.913849     187.939824   \n",
       "3            0       31  0.002195     119.859781     119.835941   \n",
       "4            0       62  0.001747     175.932865     175.934256   \n",
       "...        ...      ...       ...            ...            ...   \n",
       "3825         0    32751  0.002611     296.387479     296.365481   \n",
       "3826         0    32753  0.001190     206.063903     206.100395   \n",
       "3827         0    32758  0.004264     187.915689     187.897700   \n",
       "3828         0    32763  0.004352     307.723687     307.732623   \n",
       "3829         0    32767  0.001084     227.800017     227.809904   \n",
       "\n",
       "      book.log_return1.realized_volatility  \\\n",
       "0                                 0.004499   \n",
       "1                                 0.001204   \n",
       "2                                 0.002369   \n",
       "3                                 0.002574   \n",
       "4                                 0.001894   \n",
       "...                                    ...   \n",
       "3825                              0.002579   \n",
       "3826                              0.002206   \n",
       "3827                              0.002913   \n",
       "3828                              0.003046   \n",
       "3829                              0.001901   \n",
       "\n",
       "      book.log_return2.realized_volatility  \\\n",
       "0                                 0.006999   \n",
       "1                                 0.002476   \n",
       "2                                 0.004801   \n",
       "3                                 0.003637   \n",
       "4                                 0.003257   \n",
       "...                                    ...   \n",
       "3825                              0.003821   \n",
       "3826                              0.002847   \n",
       "3827                              0.003266   \n",
       "3828                              0.005105   \n",
       "3829                              0.002541   \n",
       "\n",
       "      book.log_return_ask1.realized_volatility  \\\n",
       "0                                     0.002476   \n",
       "1                                     0.000928   \n",
       "2                                     0.001753   \n",
       "3                                     0.001225   \n",
       "4                                     0.001075   \n",
       "...                                        ...   \n",
       "3825                                  0.001993   \n",
       "3826                                  0.001128   \n",
       "3827                                  0.001661   \n",
       "3828                                  0.002202   \n",
       "3829                                  0.001656   \n",
       "\n",
       "      book.log_return_ask2.realized_volatility  \\\n",
       "0                                     0.002684   \n",
       "1                                     0.000761   \n",
       "2                                     0.002744   \n",
       "3                                     0.001358   \n",
       "4                                     0.001080   \n",
       "...                                        ...   \n",
       "3825                                  0.001873   \n",
       "3826                                  0.001265   \n",
       "3827                                  0.001552   \n",
       "3828                                  0.003330   \n",
       "3829                                  0.001575   \n",
       "\n",
       "      book.log_return_bid1.realized_volatility  \\\n",
       "0                                     0.002602   \n",
       "1                                     0.001029   \n",
       "2                                     0.001553   \n",
       "3                                     0.001989   \n",
       "4                                     0.001343   \n",
       "...                                        ...   \n",
       "3825                                  0.000991   \n",
       "3826                                  0.001051   \n",
       "3827                                  0.002215   \n",
       "3828                                  0.001915   \n",
       "3829                                  0.001485   \n",
       "\n",
       "      book.log_return_bid2.realized_volatility  \\\n",
       "0                                     0.003072   \n",
       "1                                     0.001292   \n",
       "2                                     0.002005   \n",
       "3                                     0.002612   \n",
       "4                                     0.001377   \n",
       "...                                        ...   \n",
       "3825                                  0.000775   \n",
       "3826                                  0.001058   \n",
       "3827                                  0.002782   \n",
       "3828                                  0.002334   \n",
       "3829                                  0.002039   \n",
       "\n",
       "      trade.log_return.realized_volatility  trade.seconds_in_bucket.count  \\\n",
       "0                                 0.002006                             40   \n",
       "1                                 0.000901                             30   \n",
       "2                                 0.001961                             25   \n",
       "3                                 0.001561                             15   \n",
       "4                                 0.000871                             22   \n",
       "...                                    ...                            ...   \n",
       "3825                              0.001519                             52   \n",
       "3826                              0.001411                             28   \n",
       "3827                              0.001521                             36   \n",
       "3828                              0.001794                             53   \n",
       "3829                              0.001197                             29   \n",
       "\n",
       "      trade.size.sum  trade.order_count.mean  \n",
       "0               3179                2.750000  \n",
       "1               1289                1.900000  \n",
       "2               2161                2.720000  \n",
       "3               1962                3.933333  \n",
       "4               1791                4.045455  \n",
       "...              ...                     ...  \n",
       "3825            3450                3.057692  \n",
       "3826            4547                3.892857  \n",
       "3827            4250                3.500000  \n",
       "3828            3217                2.150943  \n",
       "3829            3679                2.413793  \n",
       "\n",
       "[3830 rows x 15 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_order_df = make_features(train, DataBlock.TRAIN)\n",
    "book_order_df = add_time_id_order(book_order_df)\n",
    "book_order_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cc5d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data shape  (3830, 16)\n",
      "train shape  (2681, 16)\n",
      "validation shape  (574, 16)\n",
      "test shape  (575, 16)\n",
      "Length of Timeseries  2681\n",
      "Length of Timeseries  574\n",
      "Length of Timeseries  575\n",
      "Length of Timeseries  2681\n",
      "Length of Timeseries  574\n",
      "Length of Timeseries  575\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tcv_agg's l2: 1.04551e-06 + 8.50765e-08\tcv_agg's RMSPE: 0.386808 + 0.012064\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tcv_agg's l2: 1.03284e-06 + 8.19042e-08\tcv_agg's RMSPE: 0.384488 + 0.0119465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tcv_agg's l2: 1.02756e-06 + 8.23267e-08\tcv_agg's RMSPE: 0.383498 + 0.0122424\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tcv_agg's l2: 1.02546e-06 + 8.1752e-08\tcv_agg's RMSPE: 0.383116 + 0.0123236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tcv_agg's l2: 1.02486e-06 + 8.14514e-08\tcv_agg's RMSPE: 0.38301 + 0.0123449\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "updating best mae value\n",
      "using sklearn metrics\n",
      "adding new model results in\n",
      "[{'model_name': 'LightGBM', 'mse': 1.5883540463448026e-06, 'rmse': 0.0012602991892184977, 'mae': 0.0008608195368535222, 'added_date': datetime.datetime(2023, 7, 21, 17, 46, 24, 221274)}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a0f3b9f64b491b890f0d63e2e79fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79caa658a48a4b87b69cc29e71c07aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 291.225, valid rmspe: 274.421\n",
      "new best:274.421142578125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924b52c427454855b4cb559bcaac9ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66bea24cda844f99a89c26d702b35a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 70.312, valid rmspe: 101.385\n",
      "new best:101.38493347167969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569ea86a26bd4ec2bedd79c9a75bd57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using sklearn metrics\n",
      "adding new model results in\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2672b1a339004cebbcf4433f1e96af4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d027bcb051c4d65a027031f2acaf788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 489.642, valid rmspe: 174.145\n",
      "new best:174.1448974609375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a39da554114ac286b2b938f1e2d693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c125916da7ab44b4aed8e3e994f41cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 544.472, valid rmspe: 248.732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70105a1f2311459792778d0c8c370559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using sklearn metrics\n",
      "adding new model results in\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccddd064ccd34078b9b37e8384cdbc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa94e6cd591344d3bc4becccbcc9ab30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5273ccc74aac40ae9c1c131277faf023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d74706dbd24b2c98461c32c51b11fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dart metrics\n",
      "adding new model results in\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be02885348b74029a172118c37eb68d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3175a48ef0094b41a166b099d519949f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9fb97e6fd34a07b9d0d7b57b34fc09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3f31d93e8346d2adb7e7593e129d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dart metrics\n",
      "adding new model results in\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a656c93f310148488d6a2c818a2a0029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbd1782d34f4402a7988d8ff234a723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dart metrics\n",
      "adding new model results in\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>added_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>2023-07-21 17:46:24.221274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.074094</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>0.197166</td>\n",
       "      <td>2023-07-21 17:46:25.357191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.361218</td>\n",
       "      <td>0.601014</td>\n",
       "      <td>0.597299</td>\n",
       "      <td>2023-07-21 17:46:27.286712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCN</td>\n",
       "      <td>0.022230</td>\n",
       "      <td>0.149098</td>\n",
       "      <td>0.117178</td>\n",
       "      <td>2023-07-21 17:47:03.867338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>0.112622</td>\n",
       "      <td>0.083827</td>\n",
       "      <td>2023-07-21 17:47:30.578260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>0.121277</td>\n",
       "      <td>0.077360</td>\n",
       "      <td>2023-07-21 17:50:41.282931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name       mse      rmse       mae                 added_date\n",
       "0     LightGBM  0.000002  0.001260  0.000861 2023-07-21 17:46:24.221274\n",
       "1          MLP  0.074094  0.272202  0.197166 2023-07-21 17:46:25.357191\n",
       "2          CNN  0.361218  0.601014  0.597299 2023-07-21 17:46:27.286712\n",
       "3          TCN  0.022230  0.149098  0.117178 2023-07-21 17:47:03.867338\n",
       "4         LSTM  0.012684  0.112622  0.083827 2023-07-21 17:47:30.578260\n",
       "5  Transformer  0.014708  0.121277  0.077360 2023-07-21 17:50:41.282931"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_experiments_multivariate(book_order_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b0505cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[books] 5.441sec\n",
      "[trades] 0.813sec\n",
      "[extra features] 0.016sec\n",
      "Index(['stock_id', 'time_id', 'target', 'book.seconds_in_bucket.count',\n",
      "       'book.wap1.sum', 'book.wap2.sum',\n",
      "       'book.log_return1.realized_volatility',\n",
      "       'book.log_return2.realized_volatility', 'book.log_return_ask1.sum',\n",
      "       'book.log_return_ask1.realized_volatility', 'book.log_return_ask2.sum',\n",
      "       'book.log_return_ask2.realized_volatility', 'book.log_return_bid1.sum',\n",
      "       'book.log_return_bid1.realized_volatility', 'book.log_return_bid2.sum',\n",
      "       'book.log_return_bid2.realized_volatility', 'book.wap_balance.sum',\n",
      "       'book.price_spread.sum', 'book.bid_spread.sum', 'book.ask_spread.sum',\n",
      "       'book.total_volume.sum', 'book.volume_imbalance.sum',\n",
      "       'trade.log_return.realized_volatility', 'trade.seconds_in_bucket.count',\n",
      "       'trade.size.sum', 'trade.order_count.mean'],\n",
      "      dtype='object')\n",
      "Total data shape  (3830, 26)\n",
      "train shape  (2681, 26)\n",
      "validation shape  (574, 26)\n",
      "test shape  (575, 26)\n",
      "Length of Timeseries  2681\n",
      "Length of Timeseries  574\n",
      "Length of Timeseries  575\n",
      "Length of Timeseries  2681\n",
      "Length of Timeseries  574\n",
      "Length of Timeseries  575\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tcv_agg's l2: 9.24065e-07 + 9.78525e-08\tcv_agg's RMSPE: 0.372768 + 0.0143505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tcv_agg's l2: 9.22858e-07 + 9.32366e-08\tcv_agg's RMSPE: 0.372604 + 0.0138048\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tcv_agg's l2: 9.20809e-07 + 9.11847e-08\tcv_agg's RMSPE: 0.372214 + 0.0134238\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tcv_agg's l2: 9.19906e-07 + 9.13836e-08\tcv_agg's RMSPE: 0.372032 + 0.0135358\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "updating best mae value\n",
      "using sklearn metrics\n",
      "value already exists in model results. So updating it\n",
      "[{'model_name': 'LightGBM', 'mse': 6.528313709711141e-06, 'rmse': 0.0025550564983403286, 'mae': 0.0014653354943799204, 'added_date': datetime.datetime(2023, 7, 21, 0, 46, 49, 564986)}, {'model_name': 'MLP', 'mse': 0.17369352640382577, 'rmse': 0.4167655532836486, 'mae': 0.23846375184248847, 'added_date': datetime.datetime(2023, 7, 21, 0, 9, 22, 345624)}, {'model_name': 'CNN', 'mse': 0.021295854406716767, 'rmse': 0.14593099193357376, 'mae': 0.12022827597796787, 'added_date': datetime.datetime(2023, 7, 21, 0, 9, 24, 912836)}, {'model_name': 'TCN', 'mse': 0.01918983, 'rmse': 0.13852736, 'mae': 0.09145093, 'added_date': datetime.datetime(2023, 7, 21, 0, 10, 0, 511405)}, {'model_name': 'LSTM', 'mse': 0.009748155, 'rmse': 0.09873275, 'mae': 0.0734687, 'added_date': datetime.datetime(2023, 7, 21, 0, 10, 28, 773225)}, {'model_name': 'Transformer', 'mse': 0.014595536, 'rmse': 0.120811984, 'mae': 0.07745529, 'added_date': datetime.datetime(2023, 7, 21, 0, 13, 44, 567319)}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faf612fe2084ecba218214e31e7419e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2860cf3b39048a0aa634fd9493ab765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 222.440, valid rmspe: 684.395\n",
      "new best:684.3953857421875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a164fe9e7cc14d848054a93ee8c60f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333b3e51499043909cfce8be548074d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 68.681, valid rmspe: 39.829\n",
      "new best:39.829139709472656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da80aad8ed5648819899fc3987bb7ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using sklearn metrics\n",
      "value already exists in model results. So updating it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d98d2f519e34230a43e9ebb41dc0651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b20d8e07c2547e981dd43269f538d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 590.160, valid rmspe: 82.274\n",
      "new best:82.27436065673828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e51bfc934347ed86fb36e27fa18732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71af70c708e4bbc8d1009e0eb630283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 409.975, valid rmspe: 39.959\n",
      "new best:39.95857620239258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965758337ee3435bb89823b437e0d689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using sklearn metrics\n",
      "value already exists in model results. So updating it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60e50e3032c4f3fb21ee04fe8b51757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0968a6ee2fb4504a926ac7caac27f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0427e5098d1943e1b8a3bc1ea4ead6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd48e0e2eac94c7e9ec9b43a8ad5cdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dart metrics\n",
      "value already exists in model results. So updating it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf66aa4b64f44fbaf2a423c5f782b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edaa377078bf4037bbc54b471f48c45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02be0d68a5974e59af740eb6744bf469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9646e8e0f54f2195360ef15ac29904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dart metrics\n",
      "value already exists in model results. So updating it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4891e33f2bef4e03b02d13cfa93776f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962e8cb1be7f416fa689207fecfd945d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dart metrics\n",
      "value already exists in model results. So updating it\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>added_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>2023-07-21 00:46:49.564986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.017422</td>\n",
       "      <td>0.131993</td>\n",
       "      <td>0.100663</td>\n",
       "      <td>2023-07-21 00:46:50.766785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.016470</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>0.109798</td>\n",
       "      <td>2023-07-21 00:46:53.433619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCN</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>0.121354</td>\n",
       "      <td>0.078984</td>\n",
       "      <td>2023-07-21 00:47:28.255966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.072466</td>\n",
       "      <td>2023-07-21 00:47:56.601013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.014665</td>\n",
       "      <td>0.121097</td>\n",
       "      <td>0.077269</td>\n",
       "      <td>2023-07-21 00:51:15.331906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name       mse      rmse       mae                 added_date\n",
       "0     LightGBM  0.000007  0.002555  0.001465 2023-07-21 00:46:49.564986\n",
       "1          MLP  0.017422  0.131993  0.100663 2023-07-21 00:46:50.766785\n",
       "2          CNN  0.016470  0.128336  0.109798 2023-07-21 00:46:53.433619\n",
       "3          TCN  0.014727  0.121354  0.078984 2023-07-21 00:47:28.255966\n",
       "4         LSTM  0.007940  0.089108  0.072466 2023-07-21 00:47:56.601013\n",
       "5  Transformer  0.014665  0.121097  0.077269 2023-07-21 00:51:15.331906"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book_trade_with_spread_features = make_features(train, DataBlock.TRAIN, add_spread_features=True)\n",
    "print(book_trade_with_spread_features.columns)\n",
    "perform_experiments_multivariate(book_trade_with_spread_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_PRECOMPUTE_FEATURES = False\n",
    "# print('USE_PRECOMPUTE_FEATURES ', USE_PRECOMPUTE_FEATURES)\n",
    "# if USE_PRECOMPUTE_FEATURES:\n",
    "#     with timer('load feather'):\n",
    "#         df = pd.read_feather(DATA_DIR + '/data-cache/features_v2.f')\n",
    "# else:\n",
    "#     print('making features ')\n",
    "#     df = make_features(train, DataBlock.TRAIN)\n",
    "#     # v2\n",
    "#     df = make_features_v2(df, DataBlock.TRAIN)\n",
    "\n",
    "    # df.to_feather(DATA_DIR + '/data-cache/features_v2.f')  # save cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('make nearest neighbor feature'):\n",
    "    df_with_nn_features = make_nearest_neighbor_feature(df)\n",
    "\n",
    "print(df_with_nn_features.shape)\n",
    "df_with_nn_features.reset_index(drop=True).to_feather(DATA_DIR + '/data-cache/optiver_df2.f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chek_null_columns(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435af70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.fillna(0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16517.385856,
   "end_time": "2022-01-23T07:01:10.301218",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-23T02:25:52.915362",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
